{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f179829-ee0d-4a09-97b8-bcfd0ef42479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import re\n",
    "# File Loading\n",
    "from trace_file_loader import get_breath_df, equalize_len_trace\n",
    "from lossplots import plot_loss\n",
    "# SkLearn Packages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Torch Packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2eb24-2b53-41a2-9aa0-0e8b7648dbfa",
   "metadata": {},
   "source": [
    "# Experiment: Training on Very Small Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a96d9-2f0f-4ba4-824d-6c7fc1670b02",
   "metadata": {},
   "source": [
    "## Load and Clean Data\n",
    "\n",
    "Data is stored in csv files. A data frame is created with the values:\n",
    "- Trace - Shortened trace to be used as model input (ex. 1400 points before start of breathold, 100 points after start of breathhold)\n",
    "- Csv_breath_holds - Breath hold length listed in CSV file\n",
    "- Data_breath_holds - Breath hold length found using the derivative of the full trace\n",
    "- Full_trace - Complete breath trace data (given in CSV file)\n",
    "- breathhold_idx - Indices of the full trace identified as breathhold due to the derivative being zero\n",
    "- bh_start_end - Indices of the full trace where the breathhold starts and ends (based on breathhold_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d54ad53-6243-4304-bd6e-b431de5fd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beforeBH_len = 1400\n",
    "afterBH_len = 100\n",
    "trace_len = beforeBH_len+afterBH_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad94f72-e350-4d1a-abfd-89aeb38b4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breath_df = get_breath_df('data_sdx_', 1400, 100, True)\n",
    "# breath_df.to_pickle('breath_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf72878-4ffa-474f-b4e8-208fcd35a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_df = pd.read_pickle('breath_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d2f0b5-4adf-49e6-9961-66ae68be57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "under2 = breath_df[abs(breath_df['Csv_breath_holds']-breath_df['Data_breath_holds'])<=2]\n",
    "under2 = under2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ccf24e1-d8c8-4b50-a808-8fd07674f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_lens = [len(row) for row in under2['Trace']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee46496-ba44-4fee-91d3-7a2c2cfeaecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average trace len: 5751.174911292006 \t75th Percentile: 6312.5 \tMax trace len: 24720\n"
     ]
    }
   ],
   "source": [
    "print('Average trace len:', np.mean(trace_lens), '\\t75th Percentile:', np.percentile(trace_lens, 75), '\\tMax trace len:',max(trace_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3abb6-8dca-436c-b4ae-b915f2d8126e",
   "metadata": {},
   "source": [
    "**Discrepancies:** Only considering files where the breathhold length listed in the CSV files is within 2 seconds of the breathhold length identified using the derivative of the trace to avoid using innacurate breath hold indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12844402-cb01-4b65-9adf-6d6d33d5d951",
   "metadata": {},
   "source": [
    "# Classification \n",
    "\n",
    "- **Goal:** Binary classification. \"Short\" breathholds are in the lower quartile of breath hold lengths and \"long\" breatholds are in the upper quartile of breath hold lengths.\n",
    "- **Encoded as:** short (0) and long (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efebb74-7c24-42c8-93b2-7c209a409259",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d24444-087d-4319-a326-b2b7b085a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "q25 = under2['Data_breath_holds'].quantile(.25)\n",
    "q75 = under2['Data_breath_holds'].quantile(.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a806a296-00f7-4021-8b78-ff6477865e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "under2 = under2[(under2['Data_breath_holds'] < q25) | (under2['Data_breath_holds'] > q75)] # only consider breathholds in upper and lower quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af361727-2e77-4375-a5d3-de89cd7b1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "under2['class'] = np.where(under2['Data_breath_holds'] < q25, 0, 1) # create encoded column: short (0), long (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff1f6b7c-db98-4dff-9576-2693b40977bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = under2[under2['class']==0]\n",
    "long = under2[under2['class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf6a329-03f7-4f08-ade8-932a475d011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955, 7) (956, 7)\n"
     ]
    }
   ],
   "source": [
    "print(long.shape, short.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfd602-16b5-4192-9ee8-d4e9cbaaa676",
   "metadata": {},
   "source": [
    "# Experiment: Try Extremely Simple Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048d4c9-be6a-430e-a0e4-d88ff79e45c0",
   "metadata": {},
   "source": [
    "## Case: 5 short, 5 long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de4b33ad-d6e2-40e7-8bf7-4ac29e790607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = under2.iloc[[29, 30, 32, 33, 35, 100, 101, 102, 103, 104]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a82aad7-f335-41ee-b747-42542ef8c626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>Csv_breath_holds</th>\n",
       "      <th>Data_breath_holds</th>\n",
       "      <th>Full_trace</th>\n",
       "      <th>breathhold_idx</th>\n",
       "      <th>bh_start_end</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[0.0016, 0.0024, 0.0034, 0.0048, 0.0063, 0.008...</td>\n",
       "      <td>11.06</td>\n",
       "      <td>11.90</td>\n",
       "      <td>[0.0016, 0.0024, 0.0034, 0.0048, 0.0063, 0.008...</td>\n",
       "      <td>[2261, 2262, 2263, 2264, 2265, 2266, 2267, 226...</td>\n",
       "      <td>(2261, 3450)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>[0.0004, 0.0007, 0.0011, 0.0016, 0.0021, 0.002...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>25.38</td>\n",
       "      <td>[0.0004, 0.0007, 0.0011, 0.0016, 0.0021, 0.002...</td>\n",
       "      <td>[2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...</td>\n",
       "      <td>(2421, 4958)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>[0.0005, 0.0012, 0.0023, 0.0034, 0.0047, 0.006...</td>\n",
       "      <td>19.82</td>\n",
       "      <td>20.79</td>\n",
       "      <td>[0.0005, 0.0012, 0.0023, 0.0034, 0.0047, 0.006...</td>\n",
       "      <td>[2227, 2228, 2229, 2230, 2231, 2232, 2233, 223...</td>\n",
       "      <td>(2227, 4305)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>[0.0023, 0.0032, 0.0044, 0.006, 0.0078, 0.0098...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.66</td>\n",
       "      <td>[0.0023, 0.0032, 0.0044, 0.006, 0.0078, 0.0098...</td>\n",
       "      <td>[2632, 2633, 2634, 2635, 2636, 2637, 2638, 263...</td>\n",
       "      <td>(2632, 3097)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>[0.0008, 0.0011, 0.0016, 0.0021, 0.0026, 0.003...</td>\n",
       "      <td>25.58</td>\n",
       "      <td>25.53</td>\n",
       "      <td>[0.0008, 0.0011, 0.0016, 0.0021, 0.0026, 0.003...</td>\n",
       "      <td>[2231, 2232, 2233, 2234, 2235, 2236, 2237, 223...</td>\n",
       "      <td>(2231, 4783)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>[0.0003, 0.0007, 0.0014, 0.0022, 0.0033, 0.004...</td>\n",
       "      <td>39.76</td>\n",
       "      <td>40.91</td>\n",
       "      <td>[0.0003, 0.0007, 0.0014, 0.0022, 0.0033, 0.004...</td>\n",
       "      <td>[2313, 2314, 2315, 2316, 2317, 2318, 2319, 232...</td>\n",
       "      <td>(2313, 6403)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>[0.0003, 0.0008, 0.0016, 0.0027, 0.0041, 0.005...</td>\n",
       "      <td>39.69</td>\n",
       "      <td>41.13</td>\n",
       "      <td>[0.0003, 0.0008, 0.0016, 0.0027, 0.0041, 0.005...</td>\n",
       "      <td>[2310, 2311, 2312, 2313, 2314, 2315, 2316, 231...</td>\n",
       "      <td>(2310, 6422)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>[0.0036, 0.0042, 0.0053, 0.0069, 0.0089, 0.011...</td>\n",
       "      <td>39.76</td>\n",
       "      <td>40.98</td>\n",
       "      <td>[0.0036, 0.0042, 0.0053, 0.0069, 0.0089, 0.011...</td>\n",
       "      <td>[2021, 2022, 2023, 2024, 2025, 2026, 2027, 202...</td>\n",
       "      <td>(2021, 6118)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>[0.0002, 0.0007, 0.0014, 0.0024, 0.0037, 0.005...</td>\n",
       "      <td>40.01</td>\n",
       "      <td>41.14</td>\n",
       "      <td>[0.0002, 0.0007, 0.0014, 0.0024, 0.0037, 0.005...</td>\n",
       "      <td>[2217, 2218, 2219, 2220, 2221, 2222, 2223, 222...</td>\n",
       "      <td>(2217, 6330)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>[0.0024, 0.0049, 0.0058, 0.0069, 0.0083, 0.01,...</td>\n",
       "      <td>39.20</td>\n",
       "      <td>40.35</td>\n",
       "      <td>[0.0024, 0.0049, 0.0058, 0.0069, 0.0083, 0.01,...</td>\n",
       "      <td>[2290, 2291, 2292, 2293, 2294, 2295, 2296, 229...</td>\n",
       "      <td>(2290, 6324)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Trace  Csv_breath_holds  \\\n",
       "132  [0.0016, 0.0024, 0.0034, 0.0048, 0.0063, 0.008...             11.06   \n",
       "133  [0.0004, 0.0007, 0.0011, 0.0016, 0.0021, 0.002...             25.53   \n",
       "135  [0.0005, 0.0012, 0.0023, 0.0034, 0.0047, 0.006...             19.82   \n",
       "136  [0.0023, 0.0032, 0.0044, 0.006, 0.0078, 0.0098...              4.67   \n",
       "139  [0.0008, 0.0011, 0.0016, 0.0021, 0.0026, 0.003...             25.58   \n",
       "220  [0.0003, 0.0007, 0.0014, 0.0022, 0.0033, 0.004...             39.76   \n",
       "221  [0.0003, 0.0008, 0.0016, 0.0027, 0.0041, 0.005...             39.69   \n",
       "222  [0.0036, 0.0042, 0.0053, 0.0069, 0.0089, 0.011...             39.76   \n",
       "223  [0.0002, 0.0007, 0.0014, 0.0024, 0.0037, 0.005...             40.01   \n",
       "224  [0.0024, 0.0049, 0.0058, 0.0069, 0.0083, 0.01,...             39.20   \n",
       "\n",
       "     Data_breath_holds                                         Full_trace  \\\n",
       "132              11.90  [0.0016, 0.0024, 0.0034, 0.0048, 0.0063, 0.008...   \n",
       "133              25.38  [0.0004, 0.0007, 0.0011, 0.0016, 0.0021, 0.002...   \n",
       "135              20.79  [0.0005, 0.0012, 0.0023, 0.0034, 0.0047, 0.006...   \n",
       "136               4.66  [0.0023, 0.0032, 0.0044, 0.006, 0.0078, 0.0098...   \n",
       "139              25.53  [0.0008, 0.0011, 0.0016, 0.0021, 0.0026, 0.003...   \n",
       "220              40.91  [0.0003, 0.0007, 0.0014, 0.0022, 0.0033, 0.004...   \n",
       "221              41.13  [0.0003, 0.0008, 0.0016, 0.0027, 0.0041, 0.005...   \n",
       "222              40.98  [0.0036, 0.0042, 0.0053, 0.0069, 0.0089, 0.011...   \n",
       "223              41.14  [0.0002, 0.0007, 0.0014, 0.0024, 0.0037, 0.005...   \n",
       "224              40.35  [0.0024, 0.0049, 0.0058, 0.0069, 0.0083, 0.01,...   \n",
       "\n",
       "                                        breathhold_idx  bh_start_end  class  \n",
       "132  [2261, 2262, 2263, 2264, 2265, 2266, 2267, 226...  (2261, 3450)      0  \n",
       "133  [2421, 2422, 2423, 2424, 2425, 2426, 2427, 242...  (2421, 4958)      0  \n",
       "135  [2227, 2228, 2229, 2230, 2231, 2232, 2233, 223...  (2227, 4305)      0  \n",
       "136  [2632, 2633, 2634, 2635, 2636, 2637, 2638, 263...  (2632, 3097)      0  \n",
       "139  [2231, 2232, 2233, 2234, 2235, 2236, 2237, 223...  (2231, 4783)      0  \n",
       "220  [2313, 2314, 2315, 2316, 2317, 2318, 2319, 232...  (2313, 6403)      1  \n",
       "221  [2310, 2311, 2312, 2313, 2314, 2315, 2316, 231...  (2310, 6422)      1  \n",
       "222  [2021, 2022, 2023, 2024, 2025, 2026, 2027, 202...  (2021, 6118)      1  \n",
       "223  [2217, 2218, 2219, 2220, 2221, 2222, 2223, 222...  (2217, 6330)      1  \n",
       "224  [2290, 2291, 2292, 2293, 2294, 2295, 2296, 229...  (2290, 6324)      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc4cfb-2ace-462e-a2f7-426df7ec05c0",
   "metadata": {},
   "source": [
    "# Split and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86a6217c-f4a5-4373-b51f-c2222577cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df['Trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f039cdfd-219b-4247-8e28-86fe59c9d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "u = np.mean([item for sublist in x_train for item in sublist])\n",
    "std = np.std([item for sublist in x_train for item in sublist])\n",
    "for row in x_train:\n",
    "    normalized_row = []\n",
    "    for x in row:\n",
    "        normalized_row.append((x-u)/std)\n",
    "    train.append(normalized_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bd9c4bc-5db7-4509-bab7-95cc6d4ce7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233fa0b-177b-47e0-aaca-997550d16eb2",
   "metadata": {},
   "source": [
    "# Equalize Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2e43e81-a45b-431a-abaa-aad91724463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68c4bec3-12fb-448e-9a4a-4fabf0f63695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_lengths(df, trim_len):\n",
    "    equal_traces = []\n",
    "    for i in range(len(df)):\n",
    "        curve = df[i]\n",
    "        if len(curve) > trim_len:\n",
    "            start_idx = len(curve)-trim_len\n",
    "            equal_traces.append(curve[start_idx:])\n",
    "        elif len(curve) < trim_len:\n",
    "            num_zeros = trim_len - len(curve)\n",
    "            \n",
    "            random_nums = (np.random.random_sample(num_zeros)-0.5)\n",
    "            box_pts = 100\n",
    "            box = np.ones(box_pts)/box_pts\n",
    "            random_nums = np.convolve(random_nums, box, mode = 'same')\n",
    "            random_nums = random_nums[:num_zeros]\n",
    "            #zeros = np.zeros([1, num_zeros])[0]\n",
    "            equal_traces.append(np.concatenate((random_nums, curve)))\n",
    "        else:\n",
    "            equal_traces.append(curve)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return np.array(equal_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "514f2966-ccb3-4cc3-93f7-594ec4bef342",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3 = equalize_lengths(x_train, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71dee5e-c047-4e3d-949c-e53a35ad5e62",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e792c22-6e51-4076-9ed5-6ec9ef086243",
   "metadata": {},
   "source": [
    "# Initialize Data for Model and Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3294b7f1-a286-42b9-ba7c-344398408cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2900eb0-d954-4b1a-ae92-63039f118b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32, requires_grad=True)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.len = len(x)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "724654d2-6141-4d48-94b2-dff6413589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = timeseries(x_train3,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0fceeaf4-3163-43f8-82db-234a99521ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([10, 10000]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape\", dataset.x.shape, dataset.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d8893-7de2-4e97-b822-30c4f14b4a61",
   "metadata": {},
   "source": [
    "# Define LSTM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "983ecf3c-2076-431f-8e4b-884d4c20b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class round_zero_decimals(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        # this can be changed for other decimal places\n",
    "        n_digits = 0                                     \n",
    "        exp = torch.pow(10,torch.tensor(n_digits))\n",
    "        return torch.div( torch.round( input*exp ), exp)\n",
    "   \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input\n",
    "\n",
    "roundActivation = round_zero_decimals.apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90beab7b-17eb-4592-945c-f99b9637a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=10, num_layers=2):\n",
    "        super(myLSTM_Model,self).__init__()\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_pack, (ht, ct) = self.lstm(x)\n",
    "        #output = output[:,-1,:] #look at yannet's code\n",
    "        output = self.linear(ht[-1])\n",
    "        return output\n",
    "        \n",
    "\n",
    "model = myLSTM_Model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36a57185-3588-4795-9e26-50f4b4a2b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myLSTM_Model(\n",
      "  (lstm): LSTM(1, 10, num_layers=2, batch_first=True)\n",
      "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abaafe09-ab0a-41a1-9b77-a33196960e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize History\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0ed150e-79eb-4f92-ad72-70ebad527c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421bc38-96ec-4f08-b358-f0c2a108af68",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ecc180e6-7555-49c5-bb19-2856dcad8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_len = len(x_train3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96446d6d-ddb9-470b-b1d7-02a024ceafb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.25210422]\n",
      " [-0.23812279]\n",
      " [-0.24643004]\n",
      " [-0.25213653]\n",
      " [-0.23882571]\n",
      " [-0.25009203]\n",
      " [-0.2445447 ]\n",
      " [-0.24664605]\n",
      " [-0.24573393]\n",
      " [-0.24446644]]\n",
      "Epoch 1 \t Training cross entropy loss: 0.7008829712867737\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.24464008]\n",
      " [-0.23230582]\n",
      " [-0.23938887]\n",
      " [-0.24466923]\n",
      " [-0.23282667]\n",
      " [-0.24275024]\n",
      " [-0.23765716]\n",
      " [-0.2395618 ]\n",
      " [-0.23873249]\n",
      " [-0.23758598]]\n",
      "Epoch 2 \t Training cross entropy loss: 0.700395941734314\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.23723754]\n",
      " [-0.22652875]\n",
      " [-0.23240232]\n",
      " [-0.23726362]\n",
      " [-0.22686912]\n",
      " [-0.23546791]\n",
      " [-0.23082167]\n",
      " [-0.23253256]\n",
      " [-0.23178482]\n",
      " [-0.23075743]]\n",
      "Epoch 3 \t Training cross entropy loss: 0.6999244689941406\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.22989368]\n",
      " [-0.22078818]\n",
      " [-0.22546825]\n",
      " [-0.22991669]\n",
      " [-0.22095007]\n",
      " [-0.2282423 ]\n",
      " [-0.22403613]\n",
      " [-0.22555622]\n",
      " [-0.22488882]\n",
      " [-0.22397874]]\n",
      "Epoch 4 \t Training cross entropy loss: 0.6994682550430298\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.22260296]\n",
      " [-0.21507764]\n",
      " [-0.21858099]\n",
      " [-0.22262289]\n",
      " [-0.21506326]\n",
      " [-0.2210679 ]\n",
      " [-0.21729493]\n",
      " [-0.21862717]\n",
      " [-0.21803884]\n",
      " [-0.21724427]]\n",
      "Epoch 5 \t Training cross entropy loss: 0.6990269422531128\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.21535856]\n",
      " [-0.20939425]\n",
      " [-0.21173477]\n",
      " [-0.21537542]\n",
      " [-0.20920539]\n",
      " [-0.21393825]\n",
      " [-0.21059272]\n",
      " [-0.21173953]\n",
      " [-0.21122928]\n",
      " [-0.21054868]]\n",
      "Epoch 6 \t Training cross entropy loss: 0.6985995769500732\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.2081529 ]\n",
      " [-0.20373487]\n",
      " [-0.20492296]\n",
      " [-0.20816676]\n",
      " [-0.20337275]\n",
      " [-0.20684603]\n",
      " [-0.20392331]\n",
      " [-0.20488663]\n",
      " [-0.20445363]\n",
      " [-0.20388585]]\n",
      "Epoch 7 \t Training cross entropy loss: 0.6981858015060425\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.20097879]\n",
      " [-0.19809563]\n",
      " [-0.19813864]\n",
      " [-0.20098962]\n",
      " [-0.19756094]\n",
      " [-0.19978403]\n",
      " [-0.19728002]\n",
      " [-0.19806151]\n",
      " [-0.19770506]\n",
      " [-0.1972491 ]]\n",
      "Epoch 8 \t Training cross entropy loss: 0.6977845430374146\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.19382937]\n",
      " [-0.19247292]\n",
      " [-0.19137505]\n",
      " [-0.1938372 ]\n",
      " [-0.1917656 ]\n",
      " [-0.19274533]\n",
      " [-0.19065626]\n",
      " [-0.19125733]\n",
      " [-0.1909768 ]\n",
      " [-0.19063179]]\n",
      "Epoch 9 \t Training cross entropy loss: 0.6973955035209656\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.18669766]\n",
      " [-0.18686308]\n",
      " [-0.1846254 ]\n",
      " [-0.1867025 ]\n",
      " [-0.1859826 ]\n",
      " [-0.18572293]\n",
      " [-0.18404545]\n",
      " [-0.18446723]\n",
      " [-0.1842621 ]\n",
      " [-0.18402742]]\n",
      "Epoch 10 \t Training cross entropy loss: 0.6970177888870239\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.1795765 ]\n",
      " [-0.18126293]\n",
      " [-0.17788294]\n",
      " [-0.17957835]\n",
      " [-0.18020798]\n",
      " [-0.17870973]\n",
      " [-0.17744109]\n",
      " [-0.17768438]\n",
      " [-0.17755422]\n",
      " [-0.17742948]]\n",
      "Epoch 11 \t Training cross entropy loss: 0.6966507434844971\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.17245862]\n",
      " [-0.17566961]\n",
      " [-0.17114106]\n",
      " [-0.17245746]\n",
      " [-0.17443831]\n",
      " [-0.17169856]\n",
      " [-0.17083701]\n",
      " [-0.17090213]\n",
      " [-0.17084676]\n",
      " [-0.1708318 ]]\n",
      "Epoch 12 \t Training cross entropy loss: 0.6962940096855164\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.1653369 ]\n",
      " [-0.17008097]\n",
      " [-0.16439368]\n",
      " [-0.1653328 ]\n",
      " [-0.16867082]\n",
      " [-0.16468264]\n",
      " [-0.16422752]\n",
      " [-0.16411427]\n",
      " [-0.1641337 ]\n",
      " [-0.16422874]]\n",
      "Epoch 13 \t Training cross entropy loss: 0.695946991443634\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.15820467]\n",
      " [-0.16449559]\n",
      " [-0.1576353 ]\n",
      " [-0.1581976 ]\n",
      " [-0.16290341]\n",
      " [-0.15765555]\n",
      " [-0.15760761]\n",
      " [-0.15731514]\n",
      " [-0.15740967]\n",
      " [-0.15761533]]\n",
      "Epoch 14 \t Training cross entropy loss: 0.6956092119216919\n",
      "y value: tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "predictions: [[-0.15105586]\n",
      " [-0.15891275]\n",
      " [-0.15086114]\n",
      " [-0.1510458 ]\n",
      " [-0.15713483]\n",
      " [-0.15061164]\n",
      " [-0.15097316]\n",
      " [-0.15049997]\n",
      " [-0.15067011]\n",
      " [-0.15098739]]\n",
      "Epoch 15 \t Training cross entropy loss: 0.6952804923057556\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    x = dataset.x\n",
    "    y = dataset.y\n",
    "    \n",
    "    # Training Loss\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    model.train()\n",
    "    \n",
    "    # Clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward Pass\n",
    "    roundActivation = round_zero_decimals.apply \n",
    "    ypred = model(x.view(-1,trace_len,1))\n",
    "    # Find the Loss\n",
    "    loss = F.binary_cross_entropy_with_logits(ypred,y.view(-1,1))   \n",
    "    # Calculate gradients\n",
    "    loss.backward()       \n",
    "    # Update Weights\n",
    "    optimizer.step()      \n",
    "    train_loss += loss.item()\n",
    "    train_preds.append(ypred)\n",
    "        \n",
    "    print(\"y value:\", y)\n",
    "    print(\"predictions:\", ypred.detach().numpy())\n",
    "\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        torch.save(model, 'lstm_bh')\n",
    "        \n",
    "    history.append(train_loss)\n",
    "    print(f'Epoch {i+1} \\t Training cross entropy loss: {train_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "083c1a38-c3d6-4670-bb45-21d9cf4cf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'lstm_bh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c0686-94e3-4457-94c3-2cde0be486dc",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "937fd5de-d9ed-4799-bcaa-30daf4a7e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)\n",
    "plt.ylim([0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
