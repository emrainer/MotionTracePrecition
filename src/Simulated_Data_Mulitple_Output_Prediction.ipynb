{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b5faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "\n",
    "\n",
    "import os, errno\n",
    "import sys\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c45f2ac-d170-47af-9f5a-6d8f9d27feb5",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14352c52-4347-43b3-b3d7-a53577daaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_data(samp_size, len_wave): \n",
    "    xs =[]\n",
    "    ys = []\n",
    "    for i in range(samp_size):\n",
    "        bh = np.random.randint(500, 4000)\n",
    "        x = np.linspace(0, 50, len_wave-bh)\n",
    "        sinewave = np.sin(x)\n",
    "        next_pt = sinewave[-1]\n",
    "        breath = np.array([sinewave[-1]] * bh)\n",
    "\n",
    "        xs.append(np.concatenate((sinewave,breath)))\n",
    "        ys.append(bh)\n",
    "    \n",
    "    return  pd.DataFrame({\"Trace\":xs, \"Breath_len\": ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6b6c32-db79-491b-92ec-3197d6cef4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_df = fake_data(100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fcab249-32d1-4555-aaa7-4b7a11918fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>Breath_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.007264210410259747, 0.0145280374921384...</td>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.005707080079268337, 0.0114139742730701...</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.006353197412559324, 0.0127061383876781...</td>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.008230359752919348, 0.0164601619815255...</td>\n",
       "      <td>3924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.007572243248271787, 0.0151440523064648...</td>\n",
       "      <td>3396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Trace  Breath_len\n",
       "0  [0.0, 0.007264210410259747, 0.0145280374921384...        3116\n",
       "1  [0.0, 0.005707080079268337, 0.0114139742730701...        1238\n",
       "2  [0.0, 0.006353197412559324, 0.0127061383876781...        2129\n",
       "3  [0.0, 0.008230359752919348, 0.0164601619815255...        3924\n",
       "4  [0.0, 0.007572243248271787, 0.0151440523064648...        3396"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breath_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c5f7b-deb9-4bad-84c9-2c872262fad3",
   "metadata": {},
   "source": [
    "## Create Windowed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c390fc25-fe97-4112-a80d-b9f249530c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trace(sequence, n_steps, n_output):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-n_output:\n",
    "            break\n",
    "\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+n_output]\n",
    "\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5645c0e6-4fdb-475b-aeea-5539d3f8993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79aa9e0-0291-420b-9f01-c7662881e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "next_pt = []\n",
    "for row in breath_df['Trace']:\n",
    "    Xs, ys = split_trace(row, 100, num_outputs)\n",
    "    traces.append(Xs)\n",
    "    next_pt.append(ys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2bacab-12f5-4912-a647-9bc133000a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces2 = [np.array(x, dtype='float32') for sublist in traces for x in sublist]\n",
    "next_pt2 = [x for sublist in next_pt for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a890c207-0cea-46cf-8292-4d624b9c476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_df2 = pd.DataFrame({\"Trace\":traces2, \"Next_pts\": next_pt2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b717e4-cd9e-4a6e-86bb-09df14b24a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>Next_pts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0072642104, 0.014528037, 0.021791099, ...</td>\n",
       "      <td>[0.6642031971676563, 0.6696160479537421, 0.674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0072642104, 0.014528037, 0.021791099, 0.029...</td>\n",
       "      <td>[0.6696160479537421, 0.6749935634699104, 0.680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.014528037, 0.021791099, 0.029053008, 0.0363...</td>\n",
       "      <td>[0.6749935634699104, 0.68033545994763, 0.68564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.021791099, 0.029053008, 0.036313385, 0.0435...</td>\n",
       "      <td>[0.68033545994763, 0.685641455497967, 0.690911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.029053008, 0.036313385, 0.04357185, 0.05082...</td>\n",
       "      <td>[0.685641455497967, 0.6909112701264595, 0.6961...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Trace  \\\n",
       "0  [0.0, 0.0072642104, 0.014528037, 0.021791099, ...   \n",
       "1  [0.0072642104, 0.014528037, 0.021791099, 0.029...   \n",
       "2  [0.014528037, 0.021791099, 0.029053008, 0.0363...   \n",
       "3  [0.021791099, 0.029053008, 0.036313385, 0.0435...   \n",
       "4  [0.029053008, 0.036313385, 0.04357185, 0.05082...   \n",
       "\n",
       "                                            Next_pts  \n",
       "0  [0.6642031971676563, 0.6696160479537421, 0.674...  \n",
       "1  [0.6696160479537421, 0.6749935634699104, 0.680...  \n",
       "2  [0.6749935634699104, 0.68033545994763, 0.68564...  \n",
       "3  [0.68033545994763, 0.685641455497967, 0.690911...  \n",
       "4  [0.685641455497967, 0.6909112701264595, 0.6961...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breath_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd5e27-0cc1-4cc4-b4ea-1ff89c551f6c",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8034fbf-f19a-4f97-b932-b9ac09b4d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = breath_df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4092fcb-5b8d-4a8b-b4e6-d31a1856fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(df['Trace'], df['Next_pts'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8bdb651-bcdf-4947-86b4-803459279953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1793b5-76aa-4496-82b7-07156a2672fc",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d4c315c-5f9d-47b7-b414-7a9ec4f0db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x_train, x_val):\n",
    "    u = np.mean([item for sublist in x_train for item in sublist])\n",
    "    std = np.std([item for sublist in x_train for item in sublist])\n",
    "    \n",
    "    train = []\n",
    "    for row in x_train:\n",
    "        normalized_row = []\n",
    "        for x in row:\n",
    "            normalized_row.append((x-u)/std)\n",
    "        train.append(normalized_row)\n",
    "    \n",
    "    val = []\n",
    "    for row in x_val:\n",
    "        normalized_row = []\n",
    "        for x in row:\n",
    "            normalized_row.append((x-u)/std)\n",
    "        val.append(normalized_row)\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d09322d0-201a-48ae-8dbd-53b12b483500",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val = normalize(X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116155ac-9816-47bb-8a4a-18d167513f05",
   "metadata": {},
   "source": [
    "## Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac48c7a0-3b43-415a-b003-637d247cfd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_series(series):\n",
    "    series = np.transpose(series)\n",
    "    return series.reshape(series.shape[0],series.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "661ddaf4-e45e-4c70-9a8d-49ddfbf22757",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = reshape_series(x_train)\n",
    "x_val = reshape_series(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c83d45f-dea2-464e-bddd-5796091fa8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = reshape_series(list(y_train))\n",
    "y_val2 = reshape_series(list(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06bf26-c66b-4f69-ae74-e072edb841ee",
   "metadata": {},
   "source": [
    "## Initialize Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ec43f79-bdd2-44fa-843b-fe6ad578a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecec2786-4d95-4971-bcd1-c20f5ba836f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69b78e30-f223-43dd-8a55-48ed3e952565",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = timeseries(x_train,y_train2)\n",
    "test_dataset = timeseries(x_val,y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54d7b75c-0cc5-4685-aa4e-8cfa9df51028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 474768, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "621608fa-5c06-45c2-8412-3ac10cba7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset,shuffle=False,batch_size=200)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False,batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8eea69-d90b-41ca-984f-3241b61c1a7a",
   "metadata": {},
   "source": [
    "## Define LSTM Encoder and Decoder (Multistep Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "236caad2-2e37-4552-acaf-a721296a3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "from torch import nn\n",
    "\n",
    "class lstm_encoder(nn.Module):\n",
    "    ''' Encodes a time series sequence '''\n",
    "    \n",
    "    def __init__(self, input_size=1, hidden_size=5, num_layers=1):\n",
    "\n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.input_size = input_size # the number of features in the input X\n",
    "        self.hidden_size = hidden_size # the number of features in the hidden state h\n",
    "        self.num_layers = num_layers # number of recurrent layers \n",
    "        \n",
    "        # define an LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, self.hidden = self.lstm(x.view(x.shape[0], x.shape[1], self.input_size))\n",
    "        \n",
    "        return output, self.hidden   # hidden gives the hidden state and cell state for the last element in the sequence \n",
    "                                     # give this to decoder\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acc6082a-5b8e-4854-8b0a-6b924ca0e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_decoder(nn.Module):\n",
    "    ''' Decodes hidden state output by encoder '''\n",
    "    \n",
    "    def __init__(self, input_size=1, hidden_size=5, num_layers=1):\n",
    "\n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size   # the number of features in the input X\n",
    "        self.hidden_size = hidden_size # the number of features in the hidden state h\n",
    "        self.num_layers = num_layers   # number of recurrent layers\n",
    "\n",
    "        # Define LSTM layer and Linear layer\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
    "                            num_layers = num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)       \n",
    "    \n",
    "    \n",
    "    def forward(self, x, encoder_hidden_states):\n",
    "        output, self.hidden = self.lstm(x.unsqueeze(0), encoder_hidden_states)\n",
    "        output = self.linear(output.squeeze(0))     \n",
    "        \n",
    "        return output, self.hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de17f6-f045-4824-87a0-1d08b17159b1",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d67156e9-70cf-44ed-81f1-6b4517065095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_seq2seq(nn.Module):\n",
    "    ''' train LSTM encoder-decoder and make predictions '''\n",
    "    \n",
    "    def __init__(self, input_size=1, hidden_size=5):\n",
    "\n",
    "        super(lstm_seq2seq, self).__init__()\n",
    "\n",
    "        self.input_size = input_size   # number of expected features in the input X\n",
    "        self.hidden_size = hidden_size # number of features in the hidden state h\n",
    "        \n",
    "        # Encoder and decoder\n",
    "        self.encoder = lstm_encoder(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.decoder = lstm_decoder(input_size=input_size, hidden_size=hidden_size)\n",
    "        \n",
    "    \n",
    "    def train_model(self, input_tensor, target_tensor, n_epochs, target_len,batch_size,learning_rate = 0.01):\n",
    "        losses = np.full(n_epochs, np.nan)\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # calculate number of batch iterations\n",
    "        n_batches = int(input_tensor.shape[1] / batch_size)\n",
    "\n",
    "        with trange(n_epochs) as tr:\n",
    "            for it in tr:\n",
    "                batch_loss = 0.\n",
    "  \n",
    "                for b in range(n_batches):\n",
    "                    # select data \n",
    "                    input_batch = input_tensor[:, b: b + batch_size, :]\n",
    "                    target_batch = target_tensor[:, b: b + batch_size, :]\n",
    "\n",
    "                    # outputs tensor\n",
    "                    outputs = torch.zeros(target_len, batch_size, input_batch.shape[2])\n",
    "\n",
    "                    # initialize hidden state\n",
    "                    encoder_hidden = self.encoder.init_hidden(batch_size)\n",
    "\n",
    "                    # zero the gradient\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # encoder outputs\n",
    "                    encoder_output, encoder_hidden = self.encoder(input_batch)\n",
    "\n",
    "                    # decoder with teacher forcing\n",
    "                    decoder_input = input_batch[-1, :, :]   # shape: (batch_size, input_size)\n",
    "                    decoder_hidden = encoder_hidden\n",
    "\n",
    "                    for t in range(target_len): \n",
    "                        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                        outputs[t] = decoder_output\n",
    "                        decoder_input = decoder_output\n",
    "\n",
    "                    # compute the loss \n",
    "                    loss = criterion(outputs, target_batch)\n",
    "                    batch_loss += loss.item()\n",
    "\n",
    "                    # backpropagation\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # loss for epoch \n",
    "                batch_loss /= n_batches \n",
    "                losses[it] = batch_loss\n",
    "\n",
    "                # progress bar \n",
    "                tr.set_postfix(loss=\"{0:.3f}\".format(batch_loss))\n",
    "\n",
    "        return losses\n",
    "\n",
    "        \n",
    "    def predict(self, input_tensor, target_len):\n",
    "        \n",
    "        # encode input_tensor\n",
    "        input_tensor = input_tensor.unsqueeze(1)     # add in batch size of 1\n",
    "        encoder_output, encoder_hidden = self.encoder(input_tensor)\n",
    "\n",
    "        # initialize tensor for predictions\n",
    "        outputs = torch.zeros(target_len, input_tensor.shape[2])\n",
    "\n",
    "        # decode input_tensor\n",
    "        decoder_input = input_tensor[-1, :, :]\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for t in range(target_len):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs[t] = decoder_output.squeeze(0)\n",
    "            decoder_input = decoder_output\n",
    "            \n",
    "        np_outputs = outputs.detach().numpy()\n",
    "        \n",
    "        return np_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be609f-0fb7-4635-9c4b-19b486b93df6",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97b2841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model parameters and train\n",
    "model1 = lstm_seq2seq(input_size=1, hidden_size=5)\n",
    "model2 = lstm_seq2seq(input_size=1, hidden_size=15)\n",
    "model3 = lstm_seq2seq(input_size=1, hidden_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba522baf-7889-41a9-8434-fd7f69bdb070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_seq2seq(\n",
      "  (encoder): lstm_encoder(\n",
      "    (lstm): LSTM(1, 5)\n",
      "  )\n",
      "  (decoder): lstm_decoder(\n",
      "    (lstm): LSTM(1, 5)\n",
      "    (linear): Linear(in_features=5, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6115216c-7842-467a-8578-ef17d425ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3]\n",
    "learning_rate = [0.1, 0.01, .001]\n",
    "hiddensizes = [5, 15, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdc12473-de5a-4756-a8b6-cd878a119f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details - Hidden Size 5 \t Learning Rate: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:01<00:00, 45.29s/it, loss=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [0.01362417 0.0006264  0.00058324 0.00057194]\n",
      "\t\t Validation MSE: 0.0004528821460516608 \tValidation MAE: 0.014601215653867882\n",
      "\n",
      "Model Details - Hidden Size 5 \t Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:17<00:00, 34.50s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [3.75165709e-03 7.20179847e-05 4.14278822e-05 3.87329729e-05]\n",
      "\t\t Validation MSE: 3.1577897990300824e-06 \tValidation MAE: 0.0012524532431996088\n",
      "\n",
      "Model Details - Hidden Size 5 \t Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:18<00:00, 34.51s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [4.82568033e-02 2.64806190e-04 6.28738835e-05 1.38501901e-05]\n",
      "\t\t Validation MSE: 2.0420970985028764e-05 \tValidation MAE: 0.0017979264441706116\n",
      "\n",
      "Model Details - Hidden Size 15 \t Learning Rate: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:20<00:00, 50.07s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [2.26881515e-03 6.11912887e-05 6.73828726e-05 4.09616939e-05]\n",
      "\t\t Validation MSE: 1.578213783955952e-05 \tValidation MAE: 0.0014136871568045178\n",
      "\n",
      "Model Details - Hidden Size 15 \t Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:21<00:00, 50.25s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [2.65330376e-03 5.55413577e-05 4.38047770e-05 2.59084104e-05]\n",
      "\t\t Validation MSE: 3.3602822517601996e-05 \tValidation MAE: 0.004016740253275858\n",
      "\n",
      "Model Details - Hidden Size 15 \t Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:19<00:00, 49.99s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [1.00294257e-02 1.44338294e-05 1.12982561e-05 8.37232424e-06]\n",
      "\t\t Validation MSE: 1.3593583667603531e-06 \tValidation MAE: 0.00072357341675059\n",
      "\n",
      "Model Details - Hidden Size 50 \t Learning Rate: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:22<00:00, 80.67s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [6.06167145e-03 1.12053224e-04 8.74379457e-05 6.13670164e-05]\n",
      "\t\t Validation MSE: 2.8767259802914138e-05 \tValidation MAE: 0.0027071941418949945\n",
      "\n",
      "Model Details - Hidden Size 50 \t Learning Rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:59<00:00, 74.94s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [1.49801040e-03 7.44473030e-05 8.95984292e-05 4.06331419e-05]\n",
      "\t\t Validation MSE: 1.36005178172019e-06 \tValidation MAE: 0.0007605575722601605\n",
      "\n",
      "Model Details - Hidden Size 50 \t Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:01<00:00, 75.37s/it, loss=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [4.44002244e-03 2.40703683e-05 2.10978043e-05 1.99685144e-05]\n",
      "\t\t Validation MSE: 1.4091032254238627e-05 \tValidation MAE: 0.0008563573783428222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0 \n",
    "for hs in hiddensizes:\n",
    "    for lr in learning_rate:\n",
    "        model = lstm_seq2seq(input_size=1, hidden_size=hs)\n",
    "        print(f'Model Details - Hidden Size {hs} \\t Learning Rate: {lr}')\n",
    "        train_loss = model.train_model(dataset.x, dataset.y, n_epochs = 4, target_len = num_outputs, batch_size = 200, learning_rate = lr)\n",
    "        print(f'Training Loss: {train_loss}')\n",
    "        valid_mse = 0.0\n",
    "        valid_mae = 0.0\n",
    "        val_preds = []\n",
    "        for i in range(len(test_dataset)):\n",
    "            x_t = test_dataset.x[:, i, :]\n",
    "            Y_pred = model.predict(x_t, target_len = num_outputs)\n",
    "            # Calculate MAE\n",
    "            valid_mae += mean_absolute_error(Y_pred,y_val2[:,i])\n",
    "            # Calculate MSE\n",
    "            valid_mse += mean_squared_error(Y_pred, y_val2[:,i])\n",
    "            val_preds.append(Y_pred)\n",
    "        modname = 'lstm_encode_decode_' + str(j)\n",
    "        torch.save(model, modname)\n",
    "        print(f'\\t\\t Validation MSE: {valid_mse/len(test_dataset)} \\tValidation MAE: {valid_mae/len(test_dataset)}')\n",
    "        print()\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de431e9-f36c-42a2-afb3-1ff48c642914",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e25d6a5-a189-43f1-bef8-1a3ef67551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_results(lstm_model, Xtrain, Ytrain, Xtest, Ytest, unscaled_xtrain, unscaled_xtest, num_rows = 4):\n",
    "\n",
    "    # input window size\n",
    "    iw = Xtrain.shape[0]\n",
    "    ow = Ytest.shape[0]\n",
    "\n",
    "    # figure setup \n",
    "    num_cols = 2\n",
    "    num_plots = num_rows * num_cols\n",
    "\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize = (10, 13))\n",
    "\n",
    "    # plot training/test predictionsabs\n",
    "    for ii in range(num_rows):\n",
    "        # train set\n",
    "        xt = reshape_series(list(unscaled_xtrain))\n",
    "        X_train_plt = Xtrain[:, ii, :]\n",
    "        Y_train_pred = lstm_model.predict(torch.from_numpy(X_train_plt).type(torch.Tensor), target_len = ow)\n",
    "\n",
    "        ax[ii, 0].plot(np.arange(0, iw), xt[:, ii, 0], 'k', linewidth = 2, label = 'Input')\n",
    "        ax[ii, 0].plot(np.arange(iw - 1, iw + ow), np.concatenate([[xt[-1, ii, 0]], Ytrain[:, ii, 0]]),\n",
    "                     color = (0.2, 0.42, 0.72), linewidth = 2, label = 'Target')\n",
    "        ax[ii, 0].plot(np.arange(iw - 1, iw + ow),  np.concatenate([[xt[-1, ii, 0]], Y_train_pred[:, 0]]),\n",
    "                     color = (0.76, 0.01, 0.01), linewidth = 2, label = 'Prediction')\n",
    "        ax[ii, 0].set_xlim([0, iw + ow - 1])\n",
    "        ax[ii, 0].set_xlabel('$t$')\n",
    "        ax[ii, 0].set_ylabel('$y$')\n",
    "\n",
    "        # test set\n",
    "        xt = reshape_series(list(unscaled_xtest))\n",
    "        X_test_plt = Xtest[:, ii, :]\n",
    "        Y_test_pred = lstm_model.predict(torch.from_numpy(X_test_plt).type(torch.Tensor), target_len = ow)\n",
    "        \n",
    "        ax[ii, 1].plot(np.arange(0, iw), xt[:, ii, 0], 'k', linewidth = 2, label = 'Input')\n",
    "        ax[ii, 1].plot(np.arange(iw - 1, iw + ow), np.concatenate([[xt[-1, ii, 0]], Ytest[:, ii, 0]]),\n",
    "                     color = (0.2, 0.42, 0.72), linewidth = 2, label = 'Target')\n",
    "        \n",
    "        ax[ii, 1].plot(np.arange(iw - 1, iw + ow), np.concatenate([[xt[-1, ii, 0]], Y_test_pred[:, 0]]),\n",
    "                      color = (0.76, 0.01, 0.01), linewidth = 2, label = 'Prediction')\n",
    "        ax[ii, 1].set_xlim([0, iw + ow - 1])\n",
    "        ax[ii, 1].set_xlabel('$t$')\n",
    "        ax[ii, 1].set_ylabel('$y$')\n",
    "        \n",
    "        # Labels\n",
    "        if ii == 0:\n",
    "            ax[ii, 0].set_title('Train')\n",
    "\n",
    "            ax[ii, 1].legend(bbox_to_anchor=(1, 1))\n",
    "            ax[ii, 1].set_title('Test')\n",
    "\n",
    "        plt.suptitle('LSTM Encoder-Decoder Prediction Examples', x = 0.445, y = 1.)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top = 0.95)\n",
    "        \n",
    "        plt.savefig('prediction_examples4.png')\n",
    "\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd9862-135f-4f04-853a-d1d9e4264f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_test_results(model, x_train, y_train2, x_val, y_val2, X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949d130-1cde-437e-b233-db56783a4286",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03f7ecbb-d95a-438d-8b18-9f5d51e6556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, ax=None, maxy=None, file=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    loss = history\n",
    "    #val_loss = history[:,1]\n",
    "    if maxy:\n",
    "        ax.set_ylim(0,maxy)\n",
    "    else:\n",
    "        ax.set_ylim(0,torch.max(loss))\n",
    "    ax.spines['top'].set_visible(False)    # turns off the top \"spine\" completely\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(.5)\n",
    "    ax.spines['bottom'].set_linewidth(.5)\n",
    "    ax.plot(loss, label='MSE')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    if file:\n",
    "        plt.savefig(f\"{file}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97e20b25-de9d-4ba4-a190-ec822c6c66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = torch.tensor(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01da0fe2-7cd4-4d97-85d5-f887a7790ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
