{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1fc48f-d96f-429d-8278-adeefc2bacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################Load Libraries  ####################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from memory_reduction import reduce_memory_usage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "\n",
    "from window_data import *\n",
    "\n",
    "import os, errno\n",
    "import sys\n",
    "from tqdm import trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b3e96-8d33-49f7-bdfd-00e9d7d60331",
   "metadata": {},
   "source": [
    "## Pre Processing & Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162afa2-8785-4e9f-b781-3cd8ea99d8c1",
   "metadata": {},
   "source": [
    "### Load and Clean Data\n",
    "\n",
    "Data is stored in csv files. We will only consider traces where the breath hold listed in the CSV and the breathold I calculated differ by fewer than 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a195991-9564-4b01-8835-cacd27c0c827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Trace</th>\n",
       "      <th>Csv_breath_holds</th>\n",
       "      <th>Data_breath_holds</th>\n",
       "      <th>Full_trace</th>\n",
       "      <th>breathhold_idx</th>\n",
       "      <th>bh_start_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.1319, 0.1363, 0.1408, 0.1452, 0.1497, 0.154...</td>\n",
       "      <td>31.29</td>\n",
       "      <td>31.69</td>\n",
       "      <td>[0.0003, 0.0006, 0.001, 0.0014, 0.0019, 0.0023...</td>\n",
       "      <td>[2661, 2662, 2663, 2664, 2665, 2666, 2667, 266...</td>\n",
       "      <td>(2661, 5829)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.4727, 0.4687, 0.4646, 0.4605, 0.4563, 0.452...</td>\n",
       "      <td>30.61</td>\n",
       "      <td>31.40</td>\n",
       "      <td>[0.0006, 0.0009, 0.0013, 0.0017, 0.0022, 0.002...</td>\n",
       "      <td>[2386, 2387, 2388, 2389, 2390, 2391, 2392, 239...</td>\n",
       "      <td>(2386, 5525)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              Trace  Csv_breath_holds  \\\n",
       "0      0  [0.1319, 0.1363, 0.1408, 0.1452, 0.1497, 0.154...             31.29   \n",
       "1      1  [0.4727, 0.4687, 0.4646, 0.4605, 0.4563, 0.452...             30.61   \n",
       "\n",
       "   Data_breath_holds                                         Full_trace  \\\n",
       "0              31.69  [0.0003, 0.0006, 0.001, 0.0014, 0.0019, 0.0023...   \n",
       "1              31.40  [0.0006, 0.0009, 0.0013, 0.0017, 0.0022, 0.002...   \n",
       "\n",
       "                                      breathhold_idx  bh_start_end  \n",
       "0  [2661, 2662, 2663, 2664, 2665, 2666, 2667, 266...  (2661, 5829)  \n",
       "1  [2386, 2387, 2388, 2389, 2390, 2391, 2392, 239...  (2386, 5525)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breath_df = pd.read_pickle('breath_df')\n",
    "under2 = breath_df[abs(breath_df['Csv_breath_holds']\\\n",
    "                       -breath_df['Data_breath_holds'])<=2].reset_index()\n",
    "under2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ab52a1-e66d-4a49-aeb9-9bbe6a5b5573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(under2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58334e7d-bfba-44f6-8ce0-6db6f968e9f4",
   "metadata": {},
   "source": [
    "### Memory Usage \n",
    "Reduce memory usage to avoid kernel crashing during normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ef096d-45a5-4e08-b3e4-3f5eb7a8b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.17 Mb from  0.26 Mb (32.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "under2 = reduce_memory_usage(under2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b323504e-0878-4d58-9aa1-8154042c592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe and rename\n",
    "df = under2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02331d-7c97-44c0-8a8d-7f25f0d3fd94",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6d9ac2-2778-40be-b01f-26e2218d95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int((len(df)) * 0.70)\n",
    "valid_size = int((len(df))*.20)\n",
    "test_size = int((len(df))*.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a845403e-c338-4b7c-9b0d-f9fa9e5a070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape is: (3355, 7)\n",
      "validation data shape is: (958, 7)\n",
      "test data shape is: (480, 7)\n"
     ]
    }
   ],
   "source": [
    "train = df.iloc[0:train_size]\n",
    "valid = df.iloc[train_size:train_size+valid_size]\n",
    "test = df.iloc[train_size+valid_size:]\n",
    "print(\"train data shape is:\",train.shape)\n",
    "print(\"validation data shape is:\",valid.shape)\n",
    "print(\"test data shape is:\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f752910-190f-4822-8e96-691b9f2d21a1",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "Normalize curves to âˆ’1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded1a3f6-6e77-4796-b1c7-7d86c7805c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(train['Trace'])\n",
    "X_val = list(valid['Trace'])\n",
    "X_test = list(test['Trace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8fc5cf-c3f6-42e2-8731-c396a3bc10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # creates the scaler\n",
    "scaler.fit(X_train)\n",
    "x_train2 = scaler.transform(X_train)\n",
    "x_val2 = scaler.transform(X_val)\n",
    "x_test2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8406e9-7124-4b27-9faf-90ecf851fa7e",
   "metadata": {},
   "source": [
    "### Sliding Window\n",
    "\n",
    "We wil use a sliding window of 100 points.\n",
    "Our target(labels) is 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc90b067-dd8e-497f-8b8d-dab2d6c39dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265330af-8166-4034-8c7c-91b00cc04fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = create_sliding_window_data(n_steps=100, num_outputs=seq_length, dataset=x_train2[:50])\n",
    "Valid = create_windowed_data(n_steps=100, num_outputs=seq_length, dataset=x_val2[:25])\n",
    "Test = create_windowed_data(n_steps=100, num_outputs=seq_length, dataset=x_test2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe2781-c19e-4680-802c-29488896f43f",
   "metadata": {},
   "source": [
    "### Define Dataset\n",
    "\n",
    "Reshape data and covert data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d2c98c4-dc41-4010-8553-0e3a156c33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_series(series):\n",
    "    series = np.transpose(np.array(series))\n",
    "    return series.reshape(series.shape[1],series.shape[0], 1)\n",
    "\n",
    "x_train = reshape_series(list(Train['Trace']))\n",
    "x_val = reshape_series(list(Valid['Trace']))\n",
    "x_test = reshape_series(list(Test['Trace']))\n",
    "\n",
    "def reshape_target(series):\n",
    "    series = np.transpose(np.array(series))\n",
    "    return series.reshape(series.shape[1],series.shape[0])\n",
    "y_train = reshape_target(list(Train['Next_pts']))\n",
    "y_val = reshape_target(list(Train['Next_pts']))\n",
    "y_test = reshape_target(list(Test['Next_pts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69d3ff9-bda8-4741-a449-699ff860d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d16301e-2e6e-4040-9625-ed96e54fe766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = timeseries(x_train, y_train)\n",
    "valid_dataset = timeseries(x_val, y_val)\n",
    "test_dataset = timeseries(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9364d41-4fbd-4757-97f7-e3d5bc97dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape is: torch.Size([70000, 100, 1])\n",
      "train y shape is: torch.Size([70000, 1])\n"
     ]
    }
   ],
   "source": [
    "print (\"train X shape is:\",train_dataset.x.shape)\n",
    "print (\"train y shape is:\",train_dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b400f375-efa5-486f-b07a-17b9b233bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train_dataset.x\n",
    "trainY = train_dataset.y\n",
    "\n",
    "valX = valid_dataset.x\n",
    "valY = valid_dataset.y\n",
    "\n",
    "testX = test_dataset.x\n",
    "testY = test_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3516a63-f51e-4c02-88a8-b21698222799",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec8ff96-075b-47ca-9aec-e7885972c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=200, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fece77-85ac-4fe0-9e05-c3d371db56c8",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869d55aa-27a6-40dd-8711-fcf33147a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 3\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "\n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31354619-e811-4289-8862-3e258862baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "num_hidden_units = 15\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=1, hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8fea4531-1fef-4dc4-8eee-94e9d7803323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 0.026432551443576813\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 0.043853711762598585\n",
      "Test loss: 0.02644255943596363\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 0.04384024618991784\n",
      "Test loss: 0.026297517120838165\n",
      "\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 0.043852296130997795\n",
      "Test loss: 0.026113780215382576\n",
      "\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 0.043884772982980526\n",
      "Test loss: 0.026221005246043205\n",
      "\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 0.04386956592755658\n",
      "Test loss: 0.026590121909976006\n",
      "\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 0.043859637549945284\n",
      "Test loss: 0.02742427960038185\n",
      "\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 0.04384628454489367\n",
      "Test loss: 0.02636834979057312\n",
      "\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 0.0438630712883813\n",
      "Test loss: 0.026132186874747276\n",
      "\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 0.04386671114712953\n",
      "Test loss: 0.02672279253602028\n",
      "\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 0.04383499239704439\n",
      "Test loss: 0.026311567053198814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "print(\"Untrained test\\n--------\")\n",
    "test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "for ix_epoch in range(10):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_model(test_loader, model, loss_function)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32d61e77-fd7a-4960-9633-0843b2f3c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'simple_lstm')\n",
    "model = ShallowRegressionLSTM(num_sensors=1, hidden_units=15)\n",
    "model = torch.load('simple_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d88e3ed-d88c-4c8f-80bc-417f6ce24b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2761], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(testX[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "07b9ce3a-d87a-4c4d-8028-dc3ad773f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(x_test, y_test, n_preds):\n",
    "    test_dataset = timeseries(x_test, y_test)\n",
    "    x = test_dataset.x\n",
    "    preds = []\n",
    "\n",
    "    for i in range(n_preds): \n",
    "        test_pred = model(x)\n",
    "        preds.append(test_pred)\n",
    "        x = torch.cat((x, test_pred.view(-1,1, 1)), 1)\n",
    "        \n",
    "    current_pred = preds[0] \n",
    "    for i in range(n_preds-1):\n",
    "        current_pred = torch.cat((current_pred.view(-1,1, i+1), \\\n",
    "                              preds[i+1].view(-1,1, 1)), -1)\n",
    "        \n",
    "    return current_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9836314a-cb5f-40be-acfb-1655953e0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = make_pred(x_test, y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c78aa63f-24d5-497e-a27e-4937af1302ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2761, 0.2769, 0.2772, 0.2772, 0.2772, 0.2772, 0.2772, 0.2772, 0.2772,\n",
       "         0.2772]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61332d0c-05f4-4310-ba9f-95b8dfa7a6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
