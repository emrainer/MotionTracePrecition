{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f179829-ee0d-4a09-97b8-bcfd0ef42479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35394c7-fd4b-468e-84e9-c8fcffe39131",
   "metadata": {},
   "source": [
    "## Narrow breath hold length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da807a0-2fb4-4158-8190-8b6f201b5713",
   "metadata": {},
   "source": [
    "## Load Files Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99c3a334-6c79-4ced-98d7-e020381f68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filelist(root):\n",
    "    '''\n",
    "    Return a fully-qualified list of filenames under root directory; \n",
    "    sort names alphabetically.\n",
    "    '''\n",
    "    allfiles = []\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            allfiles.append(os.path.join(path, name))\n",
    "    return sorted(allfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe389e-6fb5-4b6d-800c-340da37a1fd4",
   "metadata": {},
   "source": [
    "## Process Files (Helper Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af3348d2-89ac-4398-8a46-c018b7dc824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_true_seq(bool_curve):\n",
    "    '''\n",
    "    Given an array of booleans,\n",
    "    return indices of longest streak\n",
    "    of Trues\n",
    "    '''\n",
    "    longest_streak = 0\n",
    "    longest_streak_idx = []\n",
    "\n",
    "    idx = [] \n",
    "    streak = 0\n",
    "    for i in range(len(bool_curve)):\n",
    "        if bool_curve[i] == True:\n",
    "            streak += 1\n",
    "            idx.append(i)\n",
    "        else:\n",
    "            if streak > longest_streak:\n",
    "                longest_streak = streak\n",
    "                longest_streak_idx = idx     \n",
    "            streak = 0\n",
    "            idx = []\n",
    "    if streak > longest_streak and longest_streak < 150: # Not sure what this val should be\n",
    "        return [0]\n",
    "    return longest_streak_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85781c09-b9bf-440f-a8bd-4676f17dcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros(curve, bh_start_idx, bh_end_idx):\n",
    "    ''' \n",
    "    Return trace with zeros appended to beginning \n",
    "    so length of input trace is 1500\n",
    "    '''\n",
    "    front_of_curve = curve[:bh_start_idx]\n",
    "    num_zeros = 1400 - len(front_of_curve)\n",
    "    zeros = np.zeros([1, num_zeros])[0]\n",
    "    return np.concatenate((zeros, curve[:bh_end_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c5a1e22-3781-456b-8246-7d0428f0a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_curve(curve):\n",
    "    '''\n",
    "    Extract input trace from entire trace\n",
    "    '''\n",
    "    deriv = np.diff(curve)\n",
    "    breath_hold_idx = longest_true_seq(abs(deriv)<=0.001) # Not sure what this val should be\n",
    "    bh_start_idx = breath_hold_idx[0]\n",
    "    \n",
    "    if len(breath_hold_idx) < 100:\n",
    "         return [], 0, 0\n",
    "\n",
    "    bh_end_idx = breath_hold_idx[99] + 1\n",
    "    if bh_start_idx < 1400:\n",
    "        return add_zeros(curve, bh_start_idx, bh_end_idx), len(breath_hold_idx)*.01, breath_hold_idx\n",
    "    \n",
    "    else:\n",
    "        curve_start_idx = bh_start_idx - 1400\n",
    "        return curve[curve_start_idx:bh_end_idx], len(breath_hold_idx)*.01, breath_hold_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7b43c-da17-4bf6-9d28-71358207474b",
   "metadata": {},
   "source": [
    "## Create DF of Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22d75aa2-e7ac-4d3a-b0c9-b4836cfaffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_outputs_df(file_root):\n",
    "    '''\n",
    "    Given a root with files, get a dataframe of shape (5680, 2)\n",
    "    with input data traces (arrays) and \n",
    "    output data breath_holds (floats) \n",
    "    '''\n",
    "    filenames = filelist(file_root)\n",
    "    \n",
    "    orig_curves = []\n",
    "    csv_breath_holds = []\n",
    "    traces = []\n",
    "    data_breath_holds = []\n",
    "    bh_idxs = []\n",
    "    bh_start_end = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        if file.endswith('.CSV'):     \n",
    "            df = pd.read_csv(file, header=None)\n",
    "            curve = np.array(df.iloc[3:, 0], dtype='float32')\n",
    "            input_trace, bh_len, bh_idx = process_curve(curve)\n",
    "            if len(input_trace) != 0:\n",
    "                orig_curves.append(curve)\n",
    "                traces.append(input_trace)\n",
    "                csv_breath_holds.append(float(df.iloc[1,1]))\n",
    "                data_breath_holds.append(bh_len)\n",
    "                bh_idxs.append(bh_idx)\n",
    "                bh_start_end.append((bh_idx[0], bh_idx[-1]))\n",
    "    \n",
    "    data = {'Trace': traces,'Csv_breath_holds': csv_breath_holds, 'Data_breath_holds': data_breath_holds, \n",
    "            'Full_trace': orig_curves, \"breathhold_idx\": bh_idxs, 'bh_start_end':bh_start_end}\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad94f72-e350-4d1a-abfd-89aeb38b4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_df = get_inputs_outputs_df('data_sdx_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f02a7847-edd6-4b2b-b22f-d5daca34e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>Csv_breath_holds</th>\n",
       "      <th>Data_breath_holds</th>\n",
       "      <th>Full_trace</th>\n",
       "      <th>breathhold_idx</th>\n",
       "      <th>bh_start_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1319, 0.1363, 0.1408, 0.1452, 0.1497, 0.154...</td>\n",
       "      <td>31.29</td>\n",
       "      <td>31.69</td>\n",
       "      <td>[0.0003, 0.0006, 0.001, 0.0014, 0.0019, 0.0023...</td>\n",
       "      <td>[2661, 2662, 2663, 2664, 2665, 2666, 2667, 266...</td>\n",
       "      <td>(2661, 5829)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4727, 0.4687, 0.4646, 0.4605, 0.4563, 0.452...</td>\n",
       "      <td>30.61</td>\n",
       "      <td>31.40</td>\n",
       "      <td>[0.0006, 0.0009, 0.0013, 0.0017, 0.0022, 0.002...</td>\n",
       "      <td>[2386, 2387, 2388, 2389, 2390, 2391, 2392, 239...</td>\n",
       "      <td>(2386, 5525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.6466, 0.6496, 0.6526, 0.6555, 0.6583, 0.661...</td>\n",
       "      <td>14.39</td>\n",
       "      <td>18.43</td>\n",
       "      <td>[0.0002, 0.0005, 0.0008, 0.0012, 0.0016, 0.002...</td>\n",
       "      <td>[2118, 2119, 2120, 2121, 2122, 2123, 2124, 212...</td>\n",
       "      <td>(2118, 3960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0982, 0.0966, 0.095, 0.0934, 0.0919, 0.0904...</td>\n",
       "      <td>30.85</td>\n",
       "      <td>31.84</td>\n",
       "      <td>[0.0013, 0.0027, 0.0034, 0.0041, 0.005, 0.006,...</td>\n",
       "      <td>[2573, 2574, 2575, 2576, 2577, 2578, 2579, 258...</td>\n",
       "      <td>(2573, 5756)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0117, 0.0109, 0.0102, 0.0095, 0.0089, 0.008...</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.53</td>\n",
       "      <td>[0.0012, 0.0015, 0.0019, 0.0023, 0.0029, 0.003...</td>\n",
       "      <td>[2520, 2521, 2522, 2523, 2524, 2525, 2526, 252...</td>\n",
       "      <td>(2520, 5772)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Trace  Csv_breath_holds  \\\n",
       "0  [0.1319, 0.1363, 0.1408, 0.1452, 0.1497, 0.154...             31.29   \n",
       "1  [0.4727, 0.4687, 0.4646, 0.4605, 0.4563, 0.452...             30.61   \n",
       "2  [0.6466, 0.6496, 0.6526, 0.6555, 0.6583, 0.661...             14.39   \n",
       "3  [0.0982, 0.0966, 0.095, 0.0934, 0.0919, 0.0904...             30.85   \n",
       "4  [0.0117, 0.0109, 0.0102, 0.0095, 0.0089, 0.008...             32.12   \n",
       "\n",
       "   Data_breath_holds                                         Full_trace  \\\n",
       "0              31.69  [0.0003, 0.0006, 0.001, 0.0014, 0.0019, 0.0023...   \n",
       "1              31.40  [0.0006, 0.0009, 0.0013, 0.0017, 0.0022, 0.002...   \n",
       "2              18.43  [0.0002, 0.0005, 0.0008, 0.0012, 0.0016, 0.002...   \n",
       "3              31.84  [0.0013, 0.0027, 0.0034, 0.0041, 0.005, 0.006,...   \n",
       "4              32.53  [0.0012, 0.0015, 0.0019, 0.0023, 0.0029, 0.003...   \n",
       "\n",
       "                                      breathhold_idx  bh_start_end  \n",
       "0  [2661, 2662, 2663, 2664, 2665, 2666, 2667, 266...  (2661, 5829)  \n",
       "1  [2386, 2387, 2388, 2389, 2390, 2391, 2392, 239...  (2386, 5525)  \n",
       "2  [2118, 2119, 2120, 2121, 2122, 2123, 2124, 212...  (2118, 3960)  \n",
       "3  [2573, 2574, 2575, 2576, 2577, 2578, 2579, 258...  (2573, 5756)  \n",
       "4  [2520, 2521, 2522, 2523, 2524, 2525, 2526, 252...  (2520, 5772)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breath_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d2f0b5-4adf-49e6-9961-66ae68be57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "under2 = breath_df[abs(breath_df['Csv_breath_holds']-breath_df['Data_breath_holds'])<=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efebb74-7c24-42c8-93b2-7c209a409259",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6ffac48-9f40-4974-9157-ec2c150d44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "under2 = under2[(under2['Data_breath_holds']<=20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71077710-5169-4571-96f2-31da5d03d8a1",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40ce7e74-6286-463a-85a6-74aa4c7ab8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = under2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82d8b26c-9358-4a83-95b0-d9ca5b24da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Trace'], df['Data_breath_holds'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78b1203f-cd85-4a39-8bc0-0c82bed2aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "271273b9-7a12-4f75-ac76-2b21ebb955ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change type of each row from np.array to list to put into scaler\n",
    "x_train = np.array([list(row) for row in x_train])\n",
    "x_val = np.array([list(row) for row in x_val])\n",
    "x_test = np.array([list(row) for row in x_test])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f79c6b4-ca75-4514-af28-2c44b527d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # creates the scaler\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71dee5e-c047-4e3d-949c-e53a35ad5e62",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e792c22-6e51-4076-9ed5-6ec9ef086243",
   "metadata": {},
   "source": [
    "## Initialize Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3294b7f1-a286-42b9-ba7c-344398408cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2900eb0-d954-4b1a-ae92-63039f118b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "724654d2-6141-4d48-94b2-dff6413589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = timeseries(x_train,y_train)\n",
    "valid_dataset = timeseries(x_val,y_val)\n",
    "test_dataset = timeseries(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aefe9bcb-8efa-4ae6-96aa-fd97165b0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset,shuffle=True,batch_size=100)\n",
    "val_loader = DataLoader(valid_dataset,shuffle=False,batch_size=100)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False,batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d8893-7de2-4e97-b822-30c4f14b4a61",
   "metadata": {},
   "source": [
    "## Define LSTM Model (One Step Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76673e10-6bff-45f5-8cac-10f226e85f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network\n",
    "from torch import nn\n",
    "\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_Model,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1,hidden_size=100,num_layers=1,batch_first=True) # change hidden size\n",
    "        self.linear = nn.Linear(in_features=100,out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        output,_status = self.lstm(x)\n",
    "        output = output[:,-1,:]\n",
    "        #output = self.linear(torch.relu(output))\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "model = LSTM_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0ed150e-79eb-4f92-ad72-70ebad527c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Criterion and Optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421bc38-96ec-4f08-b358-f0c2a108af68",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96446d6d-ddb9-470b-b1d7-02a024ceafb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Training Loss: 92.54723834991455 \tValidation Loss: 37.607330322265625\n",
      "\t\t Training MAE: 7.635125160217285 \tValidation MAE: 5.533816337585449\n",
      "\t\t Training MSE: 92.54723644256592 \tValidation MSE: 37.607330322265625\n",
      "\n",
      "Epoch 3 \t Training Loss: 39.82405662536621 \tValidation Loss: 37.57332229614258\n",
      "\t\t Training MAE: 5.550691366195679 \tValidation MAE: 5.515478134155273\n",
      "\t\t Training MSE: 39.82405471801758 \tValidation MSE: 37.57332229614258\n",
      "\n",
      "Epoch 5 \t Training Loss: 38.40311908721924 \tValidation Loss: 40.97291946411133\n",
      "\t\t Training MAE: 5.396719336509705 \tValidation MAE: 5.6146559715271\n",
      "\t\t Training MSE: 38.403117179870605 \tValidation MSE: 40.97291564941406\n",
      "\n",
      "Epoch 7 \t Training Loss: 39.373531341552734 \tValidation Loss: 38.71126174926758\n",
      "\t\t Training MAE: 5.480738162994385 \tValidation MAE: 5.596057891845703\n",
      "\t\t Training MSE: 39.37353038787842 \tValidation MSE: 38.71126174926758\n",
      "\n",
      "Epoch 9 \t Training Loss: 41.89150619506836 \tValidation Loss: 39.846229553222656\n",
      "\t\t Training MAE: 5.791084289550781 \tValidation MAE: 5.590001106262207\n",
      "\t\t Training MSE: 41.89150428771973 \tValidation MSE: 39.84622573852539\n",
      "\n",
      "Epoch 11 \t Training Loss: 40.889047622680664 \tValidation Loss: 38.00931930541992\n",
      "\t\t Training MAE: 5.657510161399841 \tValidation MAE: 5.5662150382995605\n",
      "\t\t Training MSE: 40.88905334472656 \tValidation MSE: 38.00931930541992\n",
      "\n",
      "Epoch 13 \t Training Loss: 40.51402950286865 \tValidation Loss: 41.17085647583008\n",
      "\t\t Training MAE: 5.640061736106873 \tValidation MAE: 5.61812162399292\n",
      "\t\t Training MSE: 40.514028549194336 \tValidation MSE: 41.17085647583008\n",
      "\n",
      "Epoch 15 \t Training Loss: 43.68184852600098 \tValidation Loss: 38.09274673461914\n",
      "\t\t Training MAE: 5.855722188949585 \tValidation MAE: 5.56508207321167\n",
      "\t\t Training MSE: 43.68184947967529 \tValidation MSE: 38.092750549316406\n",
      "\n",
      "Epoch 17 \t Training Loss: 38.01087951660156 \tValidation Loss: 38.45813751220703\n",
      "\t\t Training MAE: 5.500356078147888 \tValidation MAE: 5.5750861167907715\n",
      "\t\t Training MSE: 38.01088047027588 \tValidation MSE: 38.45813751220703\n",
      "\n",
      "Epoch 19 \t Training Loss: 38.865400314331055 \tValidation Loss: 37.95278549194336\n",
      "\t\t Training MAE: 5.529913544654846 \tValidation MAE: 5.561925888061523\n",
      "\t\t Training MSE: 38.86539936065674 \tValidation MSE: 37.95278549194336\n",
      "\n",
      "Epoch 21 \t Training Loss: 41.46565628051758 \tValidation Loss: 40.81338882446289\n",
      "\t\t Training MAE: 5.745325446128845 \tValidation MAE: 5.616762638092041\n",
      "\t\t Training MSE: 41.465654373168945 \tValidation MSE: 40.81338882446289\n",
      "\n",
      "Epoch 23 \t Training Loss: 39.94335651397705 \tValidation Loss: 38.260108947753906\n",
      "\t\t Training MAE: 5.603671908378601 \tValidation MAE: 5.580113410949707\n",
      "\t\t Training MSE: 39.943355560302734 \tValidation MSE: 38.260108947753906\n",
      "\n",
      "Epoch 25 \t Training Loss: 38.50269412994385 \tValidation Loss: 38.326316833496094\n",
      "\t\t Training MAE: 5.46937620639801 \tValidation MAE: 5.573969841003418\n",
      "\t\t Training MSE: 38.50269412994385 \tValidation MSE: 38.32632064819336\n",
      "\n",
      "Epoch 27 \t Training Loss: 41.4476203918457 \tValidation Loss: 37.75759506225586\n",
      "\t\t Training MAE: 5.723034381866455 \tValidation MAE: 5.559340476989746\n",
      "\t\t Training MSE: 41.44761943817139 \tValidation MSE: 37.75759506225586\n",
      "\n",
      "Epoch 29 \t Training Loss: 43.12709045410156 \tValidation Loss: 38.047393798828125\n",
      "\t\t Training MAE: 5.769324898719788 \tValidation MAE: 5.566062927246094\n",
      "\t\t Training MSE: 43.12709045410156 \tValidation MSE: 38.047401428222656\n",
      "\n",
      "Epoch 31 \t Training Loss: 37.09240198135376 \tValidation Loss: 40.08728790283203\n",
      "\t\t Training MAE: 5.297249913215637 \tValidation MAE: 5.593354225158691\n",
      "\t\t Training MSE: 37.09240198135376 \tValidation MSE: 40.08728790283203\n",
      "\n",
      "Epoch 33 \t Training Loss: 36.20587921142578 \tValidation Loss: 37.82735061645508\n",
      "\t\t Training MAE: 5.331884026527405 \tValidation MAE: 5.559298992156982\n",
      "\t\t Training MSE: 36.20587682723999 \tValidation MSE: 37.82734298706055\n",
      "\n",
      "Epoch 35 \t Training Loss: 37.51979732513428 \tValidation Loss: 37.84116744995117\n",
      "\t\t Training MAE: 5.434854030609131 \tValidation MAE: 5.566113471984863\n",
      "\t\t Training MSE: 37.51979732513428 \tValidation MSE: 37.84116744995117\n",
      "\n",
      "Epoch 37 \t Training Loss: 37.40343952178955 \tValidation Loss: 38.34064483642578\n",
      "\t\t Training MAE: 5.473831534385681 \tValidation MAE: 5.573523044586182\n",
      "\t\t Training MSE: 37.403438568115234 \tValidation MSE: 38.34064483642578\n",
      "\n",
      "Epoch 39 \t Training Loss: 39.14599418640137 \tValidation Loss: 37.911956787109375\n",
      "\t\t Training MAE: 5.623055338859558 \tValidation MAE: 5.562562465667725\n",
      "\t\t Training MSE: 39.14599418640137 \tValidation MSE: 37.911956787109375\n",
      "\n",
      "Epoch 41 \t Training Loss: 39.85010242462158 \tValidation Loss: 37.608943939208984\n",
      "\t\t Training MAE: 5.50055468082428 \tValidation MAE: 5.549221515655518\n",
      "\t\t Training MSE: 39.8501033782959 \tValidation MSE: 37.608951568603516\n",
      "\n",
      "Epoch 43 \t Training Loss: 41.002037048339844 \tValidation Loss: 40.20002365112305\n",
      "\t\t Training MAE: 5.719677805900574 \tValidation MAE: 5.599259376525879\n",
      "\t\t Training MSE: 41.002037048339844 \tValidation MSE: 40.20002746582031\n",
      "\n",
      "Epoch 45 \t Training Loss: 39.26064491271973 \tValidation Loss: 38.0400276184082\n",
      "\t\t Training MAE: 5.583629250526428 \tValidation MAE: 5.567440509796143\n",
      "\t\t Training MSE: 39.26064395904541 \tValidation MSE: 38.04002380371094\n",
      "\n",
      "Epoch 47 \t Training Loss: 41.30452919006348 \tValidation Loss: 38.175174713134766\n",
      "\t\t Training MAE: 5.709431409835815 \tValidation MAE: 5.56367301940918\n",
      "\t\t Training MSE: 41.30452919006348 \tValidation MSE: 38.175174713134766\n",
      "\n",
      "Epoch 49 \t Training Loss: 38.34666633605957 \tValidation Loss: 40.75310516357422\n",
      "\t\t Training MAE: 5.384824872016907 \tValidation MAE: 5.624771595001221\n",
      "\t\t Training MSE: 38.34666633605957 \tValidation MSE: 40.75310516357422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    train_mse = 0.0\n",
    "    train_mae = 0.0\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        ypred = model(x.view(-1,1500,1))       \n",
    "        # Find the Loss\n",
    "        loss = criterion(ypred,y.view(-1,1))      \n",
    "        # Calculate gradients\n",
    "        loss.backward()       \n",
    "        # Update Weights\n",
    "        optimizer.step()      \n",
    "        # Calculate L1 Loss\n",
    "        train_loss += loss.item()\n",
    "        # Calculate MAE\n",
    "        ypred = ypred.detach().numpy()\n",
    "        train_mae += mean_absolute_error(ypred, y.view(-1,1))\n",
    "        # Calculate MSE\n",
    "        train_mse += mean_squared_error(ypred, y.view(-1,1))\n",
    "        # R^2\n",
    "        \n",
    "        train_preds.append(ypred)\n",
    "        \n",
    "    valid_mse = 0.0\n",
    "    valid_mae = 0.0\n",
    "    valid_loss = 0.0\n",
    "    val_preds = []\n",
    "    for x, y in val_loader:\n",
    "        # Forward Pass\n",
    "        ypred = model(x.view(-1,1500,1))\n",
    "        # Find the Loss\n",
    "        loss = criterion(ypred,y.view(-1,1))\n",
    "        # Calculate L1 Loss\n",
    "        valid_loss += loss.item()\n",
    "        # Calculate MAE\n",
    "        ypred = ypred.detach().numpy()\n",
    "        valid_mae += mean_absolute_error(ypred, y.view(-1,1))\n",
    "        # Calculate MSE\n",
    "        valid_mse += mean_squared_error(ypred, y.view(-1,1))\n",
    "        \n",
    "        val_preds.append(ypred)\n",
    "\n",
    "    history.append((train_loss/len(train_loader),valid_loss/len(val_loader)))\n",
    "    if i%2 == 0:\n",
    "        torch.save(model, 'lstm_single_output')\n",
    "        print(f'Epoch {i+1} \\t Training Loss: {train_loss/len(train_loader)} \\tValidation Loss: {valid_loss/len(val_loader)}')\n",
    "        print(f'\\t\\t Training MAE: {train_mae/len(train_loader)} \\tValidation MAE: {valid_mae/len(val_loader)}')\n",
    "        print(f'\\t\\t Training MSE: {train_mse/len(train_loader)} \\tValidation MSE: {valid_mse/len(val_loader)}')\n",
    "        print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c0686-94e3-4457-94c3-2cde0be486dc",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7491fb-a02a-4c51-9da1-34a547645a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = torch.tensor(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c1a38-c3d6-4670-bb45-21d9cf4cf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'lstm_bh_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4856509-e27e-4523-ac71-16684807c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, ax=None, maxy=None, file=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,3))\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    val_loss = history[:,1]\n",
    "\n",
    "    ax.spines['top'].set_visible(False)    # turns off the top \"spine\" completely\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(.5)\n",
    "    ax.spines['bottom'].set_linewidth(.5)\n",
    "    ax.plot(loss, label='train_loss')\n",
    "    ax.plot(val_loss, '--', label='val_loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    if file:\n",
    "        plt.savefig(f\"{file}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed3991-053e-4bbd-8b89-6537d10c1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history, maxy = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a903df-0a42-4831-af50-a39e895ac712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set actual vs predicted\n",
    "test_set = timeseries(x_test,y_test)\n",
    "test_pred = model(test_set[:][0].view(-1,1500,1)).view(-1)\n",
    "plt.scatter(test_set[:][1].view(-1), test_pred.detach().numpy(),label='predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "416656c0-b79b-4c7c-9fe4-691445b0c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model(test_set[:][0].view(-1,1500,1)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6c7a8eb-1bb1-4af6-8da0-30f82f34c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34.5000, 35.4700, 35.4200, 30.7400, 32.5900, 36.6200, 27.0900, 30.7700,\n",
       "        39.9000, 27.1700, 56.7200, 29.1300, 33.1000, 27.2000, 55.6500, 12.7800,\n",
       "        31.0900,  2.1300, 29.9400, 59.4200, 45.8600, 10.7100, 30.6700, 46.5500,\n",
       "        29.9400, 36.9900, 30.5700, 38.6600, 36.1900, 25.6800, 31.1600, 29.9100,\n",
       "        29.4100, 34.8500, 31.5000, 43.6200, 33.9100, 29.2400, 41.3500, 27.9700,\n",
       "        32.8200, 30.5400, 31.5300, 34.6700, 39.3200, 41.0200, 34.2600, 40.2400,\n",
       "        39.4200, 30.6700, 26.7400,  1.2700, 42.9900, 42.3600, 10.9300, 29.3100,\n",
       "        26.9200, 46.3000, 50.6700, 29.5700, 38.3100, 32.8500, 36.8900, 41.7700,\n",
       "        31.3700, 46.0500, 36.8400, 25.8100, 34.0800, 30.5800, 29.3100, 35.6300,\n",
       "        32.2100, 33.9400, 38.4000, 41.6600, 52.6500, 30.9000, 36.3100,  1.5300,\n",
       "        31.0000, 26.7800,  5.1700, 29.5800, 29.9500, 22.6600, 33.0200, 21.0000,\n",
       "        42.2700,  1.8600, 26.1800, 30.0400, 36.3600, 34.3200, 58.8600, 35.4300,\n",
       "        16.1700, 22.1900, 26.3200, 37.6900, 40.0300, 44.9200, 44.2000, 33.4100,\n",
       "        39.5100, 27.9600, 31.1000, 35.4200, 31.4100, 30.8300, 42.2900,  3.1000,\n",
       "        31.9500, 31.1000, 34.4800, 30.1400, 29.3900, 32.6900, 36.1600, 31.3800,\n",
       "         1.0100, 29.6700,  1.0000, 30.4100, 34.7800, 31.5000, 31.2500, 32.4500,\n",
       "        27.8400, 43.9300, 50.4200, 36.8900, 19.5600, 33.3400, 32.7100, 55.6400,\n",
       "        30.8600,  2.7500, 36.5800, 39.5600, 26.0200, 31.0000, 33.7800, 36.4900,\n",
       "        29.3700, 30.4100, 25.6600, 37.1200, 28.4600,  2.2900, 31.1200, 20.5200,\n",
       "        30.8400, 50.0800, 41.0900, 36.4000, 36.1600, 41.4200, 22.3400, 37.7100,\n",
       "        41.6700, 28.4400, 41.9900, 30.2600, 28.6700, 36.2100, 38.4100, 34.6300,\n",
       "        40.4100,  4.1400, 27.4000, 35.2700, 34.1400, 29.4300, 29.5200, 32.4600,\n",
       "        60.7500, 18.5600, 32.7800, 32.9000,  1.9100, 25.5100, 17.8300, 29.2800,\n",
       "        23.2300, 36.4700,  3.9500, 30.6800, 41.2500, 32.8700, 40.8500, 24.7000,\n",
       "        21.8600, 33.1200, 22.0200, 41.2300, 29.1100, 11.0700, 30.9300, 33.5400,\n",
       "        28.3200,  9.4000, 30.5400, 11.9300, 41.6100, 12.4900, 40.8700, 29.4100,\n",
       "        31.7400, 31.3200, 25.3400, 46.0800, 33.5600, 33.7800, 45.8200, 60.3800,\n",
       "        14.2200, 39.1700, 36.0700, 37.0500, 30.9100, 28.3100, 32.0600, 32.8100,\n",
       "        38.3300,  3.3500, 69.7600, 37.8900, 61.7200, 27.3300, 24.8500, 41.8300,\n",
       "        35.0300, 32.8900, 22.5800, 27.2800, 30.4900, 37.5300, 35.7000, 21.8100,\n",
       "         1.9700, 33.4500,  2.3700, 27.1900, 34.3800, 30.7500, 34.1900, 32.5300,\n",
       "        40.7400, 61.5400, 29.7200, 37.4800, 25.7300, 28.5800,  1.3400, 56.8000,\n",
       "        38.2200, 30.5600, 24.5600, 43.1500, 31.0200, 24.2200, 33.7700, 30.5200,\n",
       "        41.3200, 30.5900, 28.8400, 52.8400, 33.2400, 31.2400, 41.5800, 36.9000,\n",
       "        33.5700, 15.2000, 31.2700, 30.0000, 35.2500,  1.4200, 39.9000, 13.6200,\n",
       "        34.4300, 36.8100, 35.9900, 23.7000, 41.1100, 32.4700, 36.0500, 36.1000,\n",
       "        31.6300, 43.5500, 34.6700, 27.8700, 36.8700, 20.2500, 39.6300, 40.5700,\n",
       "         7.2600, 40.5100,  8.1400, 33.9200, 43.7700, 36.7000, 30.7600, 14.3900,\n",
       "        28.8300, 12.8400, 25.6800, 39.3900, 24.7300, 49.1900, 25.9200, 31.2200,\n",
       "        21.8400, 30.5600, 27.0100, 32.7300, 37.5100, 38.7600, 22.6000, 30.9800,\n",
       "        32.5300,  7.3100, 27.4800, 26.1900, 39.7700, 40.5000, 30.8500, 11.6300,\n",
       "        25.1100, 37.7000, 14.7600,  1.6000, 34.8300, 31.4400, 39.0200, 28.8800,\n",
       "        30.3400,  9.6000, 25.7300, 22.4700, 21.9200,  9.9300, 30.1300, 37.5100,\n",
       "        33.2500, 27.9700, 29.4000, 37.1400, 38.1200, 33.8400, 35.9700, 32.3900,\n",
       "        32.8000, 39.0700, 29.3100, 32.1200, 30.4100, 40.9600, 37.2300, 40.9000,\n",
       "        39.8700, 31.0300, 39.3300, 38.9800, 30.1700, 31.2200, 19.2900, 29.8300,\n",
       "        55.5300, 31.9100, 33.7100, 37.7300, 39.7000, 33.4100, 26.4700, 32.9100,\n",
       "         6.0800, 47.0300, 37.0200, 31.7600, 21.8800, 19.5600, 31.6600, 30.2300,\n",
       "        32.3800, 34.1800, 25.1900, 22.4400, 34.5400, 31.2800, 25.2100, 35.9400,\n",
       "        41.2100, 32.8000, 40.8500, 26.1900, 36.6900, 36.9000, 30.3400, 25.7300,\n",
       "        34.1300, 20.4700, 41.3600, 30.3500, 47.3800, 41.4500, 22.0000, 31.8600,\n",
       "        22.1600, 37.0800, 34.3200, 41.6000, 31.2500, 21.9800, 41.8100, 34.7300,\n",
       "        40.5300, 25.6300, 40.3300, 41.3700, 32.8800, 42.8100, 27.0800, 30.3900,\n",
       "        16.1900, 31.5500, 31.1000, 32.9500, 35.8100, 31.1100, 41.0300, 41.8300,\n",
       "        29.0900, 22.0400, 33.3000, 33.4100, 36.4500, 36.9100, 35.1200, 31.0400,\n",
       "        35.9500, 30.3400, 35.8200, 19.8100, 26.0000, 21.9200, 25.2900, 30.5200,\n",
       "        31.2300, 41.6400, 35.9600, 55.8700, 32.8200, 40.4700, 31.8300, 30.3400,\n",
       "        30.8100, 21.9300, 34.2200, 21.1000, 26.8100, 22.3000, 37.8000, 26.0200,\n",
       "        26.0900, 35.3900, 21.8000,  2.0100, 40.4700, 27.7800, 29.9300, 41.0600,\n",
       "        30.7200, 27.1000, 29.5000, 23.7000, 31.9700, 61.1000, 22.1200,  8.0700,\n",
       "        30.1300, 42.0500, 30.5600, 31.8500, 62.9000, 37.8000, 22.0900, 37.6800,\n",
       "        34.3800, 32.5700, 34.6900, 31.0700, 31.6000, 42.7000, 39.3100, 38.2200,\n",
       "        32.2600, 25.4200, 27.4600, 26.3100, 32.8500, 30.2900, 35.4200, 38.8000,\n",
       "        29.7400, 38.6100, 34.8600, 37.0600, 31.5800, 44.4400, 33.4900, 31.2300,\n",
       "        18.8500, 36.8100, 31.8500, 35.8300, 30.1400,  8.8500, 33.8700, 33.7700,\n",
       "        37.1600, 31.6700, 36.4100, 37.0500, 25.0000, 37.4900, 35.9500, 39.5100,\n",
       "        36.2700, 35.7800, 22.8300, 44.8600, 30.5900, 33.7600, 38.3400, 22.0900,\n",
       "        31.4700, 40.7000, 46.3000, 37.3200, 26.8800, 13.2000, 11.7800, 64.3700,\n",
       "        30.0900,  1.7600, 31.1500, 32.5800, 30.4600, 27.8600, 40.2400, 30.8900,\n",
       "        29.7900, 10.0300, 52.9500,  2.6100, 32.0400, 39.0900, 30.6700, 34.3400,\n",
       "        28.4700, 14.7100, 36.9500, 25.3800, 30.6700, 33.8700, 29.7400, 30.0000,\n",
       "        49.4100, 34.7700, 39.5500, 39.0100, 33.7500, 32.5700, 36.2600, 31.6900,\n",
       "        35.9500, 30.4700,  4.7000, 37.1000, 48.2100, 16.0300, 22.0900,  1.6400,\n",
       "        34.7800, 32.2300, 35.8400, 36.1200, 40.9600, 29.1300,  9.3200, 38.8900,\n",
       "        15.1100, 39.5900, 21.9900, 40.1000, 32.6400, 37.0900, 34.2600, 26.4000,\n",
       "        30.8700, 31.9100, 26.5800, 28.1100, 35.1800, 41.9200, 38.1200, 29.8200,\n",
       "        26.8100, 31.1500, 33.8300, 40.3100, 22.2600, 26.2800, 24.6700, 40.8600,\n",
       "        12.3400, 39.5800, 45.9900, 30.6700, 36.6200, 26.4800, 35.8300, 26.4900,\n",
       "        30.4400, 38.2000, 37.9900, 29.8900, 41.3600, 37.4500, 12.9200, 34.4900,\n",
       "        33.0000, 32.3100, 31.0900, 36.4500, 40.6600, 30.7600, 41.5300, 47.2500,\n",
       "        47.3700, 28.9600, 36.4500, 10.0200, 31.6200, 31.9400, 25.7500, 24.9000,\n",
       "        38.4100, 30.2400, 29.0400, 22.9100, 36.6900, 18.4000, 32.7700, 52.5900,\n",
       "        35.0500, 44.1600,  5.7000, 37.3000, 39.0200, 32.4800, 40.1700, 38.5600,\n",
       "        18.8400, 31.7900, 36.1700, 32.4300, 39.1900, 34.0500, 35.0800, 39.9000,\n",
       "        30.7600, 35.5900, 34.1300, 30.1800, 32.4000, 35.5300, 37.7600, 29.9300,\n",
       "        35.1500, 36.5900, 25.2000, 30.3500, 27.0500, 28.0600, 30.5700, 40.6200,\n",
       "        41.8600, 26.1800, 42.9400, 31.3800, 31.4600, 59.2600, 30.6900, 32.3200,\n",
       "        40.9100, 36.4300, 31.2300, 29.5800, 31.7100, 37.3500, 30.3100, 32.6000,\n",
       "        33.2800, 17.7600, 31.8100, 35.7600, 13.0900, 31.0500, 13.9700, 31.1300,\n",
       "        35.5800, 29.3600, 30.6300, 45.4200,  5.8000, 38.4900, 43.1600])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:][1].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4958e25-daf1-4afb-84bc-7af95c4bc6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206,\n",
       "        31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206, 31.9206],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166a699-63ba-4ec3-8b44-6f189a37d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210faf69-ae75-4de3-bf52-530b0cab0661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
