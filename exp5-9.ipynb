{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f179829-ee0d-4a09-97b8-bcfd0ef42479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35394c7-fd4b-468e-84e9-c8fcffe39131",
   "metadata": {},
   "source": [
    "## Normal training/val/test split, Hidden layers 150, 100, 50, 15, 10 num layers 3, adjusted learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da807a0-2fb4-4158-8190-8b6f201b5713",
   "metadata": {},
   "source": [
    "## Load Files Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c3a334-6c79-4ced-98d7-e020381f68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filelist(root):\n",
    "    '''\n",
    "    Return a fully-qualified list of filenames under root directory; \n",
    "    sort names alphabetically.\n",
    "    '''\n",
    "    allfiles = []\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            allfiles.append(os.path.join(path, name))\n",
    "    return sorted(allfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe389e-6fb5-4b6d-800c-340da37a1fd4",
   "metadata": {},
   "source": [
    "## Process Files (Helper Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3348d2-89ac-4398-8a46-c018b7dc824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_true_seq(bool_curve):\n",
    "    '''\n",
    "    Given an array of booleans,\n",
    "    return indices of longest streak\n",
    "    of Trues\n",
    "    '''\n",
    "    longest_streak = 0\n",
    "    longest_streak_idx = []\n",
    "\n",
    "    idx = [] \n",
    "    streak = 0\n",
    "    for i in range(len(bool_curve)):\n",
    "        if bool_curve[i] == True:\n",
    "            streak += 1\n",
    "            idx.append(i)\n",
    "        else:\n",
    "            if streak > longest_streak:\n",
    "                longest_streak = streak\n",
    "                longest_streak_idx = idx     \n",
    "            streak = 0\n",
    "            idx = []\n",
    "    if streak > longest_streak and longest_streak < 150: # Not sure what this val should be\n",
    "        return [0]\n",
    "    return longest_streak_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85781c09-b9bf-440f-a8bd-4676f17dcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros(curve, bh_start_idx, bh_end_idx):\n",
    "    ''' \n",
    "    Return trace with zeros appended to beginning \n",
    "    so length of input trace is 1500\n",
    "    '''\n",
    "    front_of_curve = curve[:bh_start_idx]\n",
    "    num_zeros = 1400 - len(front_of_curve)\n",
    "    zeros = np.zeros([1, num_zeros])[0]\n",
    "    return np.concatenate((zeros, curve[:bh_end_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5a1e22-3781-456b-8246-7d0428f0a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_curve(curve):\n",
    "    '''\n",
    "    Extract input trace from entire trace\n",
    "    '''\n",
    "    deriv = np.diff(curve)\n",
    "    breath_hold_idx = longest_true_seq(abs(deriv)<=0.001) # Not sure what this val should be\n",
    "    bh_start_idx = breath_hold_idx[0]\n",
    "    \n",
    "    if len(breath_hold_idx) < 100:\n",
    "         return [], 0, 0\n",
    "\n",
    "    bh_end_idx = breath_hold_idx[99] + 1\n",
    "    if bh_start_idx < 1400:\n",
    "        return add_zeros(curve, bh_start_idx, bh_end_idx), len(breath_hold_idx)*.01, breath_hold_idx\n",
    "    \n",
    "    else:\n",
    "        curve_start_idx = bh_start_idx - 1400\n",
    "        return curve[curve_start_idx:bh_end_idx], len(breath_hold_idx)*.01, breath_hold_idx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7b43c-da17-4bf6-9d28-71358207474b",
   "metadata": {},
   "source": [
    "## Create DF of Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d75aa2-e7ac-4d3a-b0c9-b4836cfaffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_outputs_df(file_root):\n",
    "    '''\n",
    "    Given a root with files, get a dataframe of shape (5680, 2)\n",
    "    with input data traces (arrays) and \n",
    "    output data breath_holds (floats) \n",
    "    '''\n",
    "    filenames = filelist(file_root)\n",
    "    \n",
    "    orig_curves = []\n",
    "    csv_breath_holds = []\n",
    "    traces = []\n",
    "    data_breath_holds = []\n",
    "    bh_idxs = []\n",
    "    bh_start_end = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        if file.endswith('.CSV'):     \n",
    "            df = pd.read_csv(file, header=None)\n",
    "            curve = np.array(df.iloc[3:, 0], dtype='float32')\n",
    "            input_trace, bh_len, bh_idx = process_curve(curve)\n",
    "            if len(input_trace) != 0:\n",
    "                orig_curves.append(curve)\n",
    "                traces.append(input_trace)\n",
    "                csv_breath_holds.append(float(df.iloc[1,1]))\n",
    "                data_breath_holds.append(bh_len)\n",
    "                bh_idxs.append(bh_idx)\n",
    "                bh_start_end.append((bh_idx[0], bh_idx[-1]))\n",
    "    \n",
    "    data = {'Trace': traces,'Csv_breath_holds': csv_breath_holds, 'Data_breath_holds': data_breath_holds, \n",
    "            'Full_trace': orig_curves, \"breathhold_idx\": bh_idxs, 'bh_start_end':bh_start_end}\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad94f72-e350-4d1a-abfd-89aeb38b4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "breath_df = get_inputs_outputs_df('data_sdx_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02a7847-edd6-4b2b-b22f-d5daca34e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trace</th>\n",
       "      <th>Csv_breath_holds</th>\n",
       "      <th>Data_breath_holds</th>\n",
       "      <th>Full_trace</th>\n",
       "      <th>breathhold_idx</th>\n",
       "      <th>bh_start_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1319, 0.1363, 0.1408, 0.1452, 0.1497, 0.154...</td>\n",
       "      <td>31.29</td>\n",
       "      <td>31.69</td>\n",
       "      <td>[0.0003, 0.0006, 0.001, 0.0014, 0.0019, 0.0023...</td>\n",
       "      <td>[2661, 2662, 2663, 2664, 2665, 2666, 2667, 266...</td>\n",
       "      <td>(2661, 5829)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4727, 0.4687, 0.4646, 0.4605, 0.4563, 0.452...</td>\n",
       "      <td>30.61</td>\n",
       "      <td>31.40</td>\n",
       "      <td>[0.0006, 0.0009, 0.0013, 0.0017, 0.0022, 0.002...</td>\n",
       "      <td>[2386, 2387, 2388, 2389, 2390, 2391, 2392, 239...</td>\n",
       "      <td>(2386, 5525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.6466, 0.6496, 0.6526, 0.6555, 0.6583, 0.661...</td>\n",
       "      <td>14.39</td>\n",
       "      <td>18.43</td>\n",
       "      <td>[0.0002, 0.0005, 0.0008, 0.0012, 0.0016, 0.002...</td>\n",
       "      <td>[2118, 2119, 2120, 2121, 2122, 2123, 2124, 212...</td>\n",
       "      <td>(2118, 3960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0982, 0.0966, 0.095, 0.0934, 0.0919, 0.0904...</td>\n",
       "      <td>30.85</td>\n",
       "      <td>31.84</td>\n",
       "      <td>[0.0013, 0.0027, 0.0034, 0.0041, 0.005, 0.006,...</td>\n",
       "      <td>[2573, 2574, 2575, 2576, 2577, 2578, 2579, 258...</td>\n",
       "      <td>(2573, 5756)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0117, 0.0109, 0.0102, 0.0095, 0.0089, 0.008...</td>\n",
       "      <td>32.12</td>\n",
       "      <td>32.53</td>\n",
       "      <td>[0.0012, 0.0015, 0.0019, 0.0023, 0.0029, 0.003...</td>\n",
       "      <td>[2520, 2521, 2522, 2523, 2524, 2525, 2526, 252...</td>\n",
       "      <td>(2520, 5772)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Trace  Csv_breath_holds  \\\n",
       "0  [0.1319, 0.1363, 0.1408, 0.1452, 0.1497, 0.154...             31.29   \n",
       "1  [0.4727, 0.4687, 0.4646, 0.4605, 0.4563, 0.452...             30.61   \n",
       "2  [0.6466, 0.6496, 0.6526, 0.6555, 0.6583, 0.661...             14.39   \n",
       "3  [0.0982, 0.0966, 0.095, 0.0934, 0.0919, 0.0904...             30.85   \n",
       "4  [0.0117, 0.0109, 0.0102, 0.0095, 0.0089, 0.008...             32.12   \n",
       "\n",
       "   Data_breath_holds                                         Full_trace  \\\n",
       "0              31.69  [0.0003, 0.0006, 0.001, 0.0014, 0.0019, 0.0023...   \n",
       "1              31.40  [0.0006, 0.0009, 0.0013, 0.0017, 0.0022, 0.002...   \n",
       "2              18.43  [0.0002, 0.0005, 0.0008, 0.0012, 0.0016, 0.002...   \n",
       "3              31.84  [0.0013, 0.0027, 0.0034, 0.0041, 0.005, 0.006,...   \n",
       "4              32.53  [0.0012, 0.0015, 0.0019, 0.0023, 0.0029, 0.003...   \n",
       "\n",
       "                                      breathhold_idx  bh_start_end  \n",
       "0  [2661, 2662, 2663, 2664, 2665, 2666, 2667, 266...  (2661, 5829)  \n",
       "1  [2386, 2387, 2388, 2389, 2390, 2391, 2392, 239...  (2386, 5525)  \n",
       "2  [2118, 2119, 2120, 2121, 2122, 2123, 2124, 212...  (2118, 3960)  \n",
       "3  [2573, 2574, 2575, 2576, 2577, 2578, 2579, 258...  (2573, 5756)  \n",
       "4  [2520, 2521, 2522, 2523, 2524, 2525, 2526, 252...  (2520, 5772)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breath_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d2f0b5-4adf-49e6-9961-66ae68be57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "under2 = breath_df[abs(breath_df['Csv_breath_holds']-breath_df['Data_breath_holds'])<=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efebb74-7c24-42c8-93b2-7c209a409259",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71077710-5169-4571-96f2-31da5d03d8a1",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ce7e74-6286-463a-85a6-74aa4c7ab8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = under2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82d8b26c-9358-4a83-95b0-d9ca5b24da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Trace'], df['Data_breath_holds'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b1203f-cd85-4a39-8bc0-0c82bed2aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "271273b9-7a12-4f75-ac76-2b21ebb955ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change type of each row from np.array to list to put into scaler\n",
    "x_train = np.array([list(row) for row in x_train])\n",
    "x_val = np.array([list(row) for row in x_val])\n",
    "x_test = np.array([list(row) for row in x_test])\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f79c6b4-ca75-4514-af28-2c44b527d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # creates the scaler\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71dee5e-c047-4e3d-949c-e53a35ad5e62",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e792c22-6e51-4076-9ed5-6ec9ef086243",
   "metadata": {},
   "source": [
    "## Initialize Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3294b7f1-a286-42b9-ba7c-344398408cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2900eb0-d954-4b1a-ae92-63039f118b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "724654d2-6141-4d48-94b2-dff6413589ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = timeseries(x_train,y_train)\n",
    "valid_dataset = timeseries(x_val,y_val)\n",
    "test_dataset = timeseries(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aefe9bcb-8efa-4ae6-96aa-fd97165b0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset,shuffle=True,batch_size=100)\n",
    "val_loader = DataLoader(valid_dataset,shuffle=False,batch_size=100)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False,batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d8893-7de2-4e97-b822-30c4f14b4a61",
   "metadata": {},
   "source": [
    "## Define LSTM Model (One Step Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76673e10-6bff-45f5-8cac-10f226e85f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network\n",
    "from torch import nn\n",
    "\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_Model,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1,hidden_size=10,num_layers=3,batch_first=True) # change hidden size\n",
    "        self.linear = nn.Linear(in_features=10,out_features=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        output,_status = self.lstm(x)\n",
    "        output = output[:,-1,:]\n",
    "        #output = self.linear(torch.relu(output))\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "model = LSTM_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0ed150e-79eb-4f92-ad72-70ebad527c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Criterion and Optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421bc38-96ec-4f08-b358-f0c2a108af68",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96446d6d-ddb9-470b-b1d7-02a024ceafb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Training Loss: 489.92166333879743 \tValidation Loss: 110.15669822692871\n",
      "\t\t Training MAE: 18.616074998038155 \tValidation MAE: 7.517296195030212\n",
      "\t\t Training MSE: 489.92166028703963 \tValidation MSE: 110.15669250488281\n",
      "\n",
      "Epoch 3 \t Training Loss: 116.32669372558594 \tValidation Loss: 107.31979751586914\n",
      "\t\t Training MAE: 7.452528572082519 \tValidation MAE: 7.364525198936462\n",
      "\t\t Training MSE: 116.32669154575893 \tValidation MSE: 107.31980514526367\n",
      "\n",
      "Epoch 5 \t Training Loss: 116.26273520333426 \tValidation Loss: 107.26293754577637\n",
      "\t\t Training MAE: 7.441749722617013 \tValidation MAE: 7.37067449092865\n",
      "\t\t Training MSE: 116.26273760114397 \tValidation MSE: 107.26294136047363\n",
      "\n",
      "Epoch 7 \t Training Loss: 117.14424220493862 \tValidation Loss: 107.26391983032227\n",
      "\t\t Training MAE: 7.481050041743687 \tValidation MAE: 7.3730762004852295\n",
      "\t\t Training MSE: 117.14424373081752 \tValidation MSE: 107.26392555236816\n",
      "\n",
      "Epoch 9 \t Training Loss: 116.46087940761021 \tValidation Loss: 107.2758560180664\n",
      "\t\t Training MAE: 7.455965042114258 \tValidation MAE: 7.376220464706421\n",
      "\t\t Training MSE: 116.46087602887835 \tValidation MSE: 107.27585983276367\n",
      "\n",
      "Epoch 11 \t Training Loss: 116.98987819126674 \tValidation Loss: 107.54806518554688\n",
      "\t\t Training MAE: 7.459018121446882 \tValidation MAE: 7.366311550140381\n",
      "\t\t Training MSE: 116.98987448556083 \tValidation MSE: 107.54806137084961\n",
      "\n",
      "Epoch 13 \t Training Loss: 117.26360081263951 \tValidation Loss: 107.27304649353027\n",
      "\t\t Training MAE: 7.482646151951381 \tValidation MAE: 7.375693440437317\n",
      "\t\t Training MSE: 117.26360277448381 \tValidation MSE: 107.27304649353027\n",
      "\n",
      "Epoch 15 \t Training Loss: 116.86211700439453 \tValidation Loss: 107.32100677490234\n",
      "\t\t Training MAE: 7.46618766784668 \tValidation MAE: 7.364472150802612\n",
      "\t\t Training MSE: 116.86211504255023 \tValidation MSE: 107.32099723815918\n",
      "\n",
      "Epoch 17 \t Training Loss: 117.13209359305246 \tValidation Loss: 107.29703903198242\n",
      "\t\t Training MAE: 7.471718229566302 \tValidation MAE: 7.379515290260315\n",
      "\t\t Training MSE: 117.13209424700055 \tValidation MSE: 107.29704093933105\n",
      "\n",
      "Epoch 19 \t Training Loss: 116.70006670270648 \tValidation Loss: 107.27114677429199\n",
      "\t\t Training MAE: 7.4568362780979704 \tValidation MAE: 7.375296473503113\n",
      "\t\t Training MSE: 116.70006583077567 \tValidation MSE: 107.2711410522461\n",
      "\n",
      "Epoch 21 \t Training Loss: 117.25286712646485 \tValidation Loss: 107.41996002197266\n",
      "\t\t Training MAE: 7.471756213051933 \tValidation MAE: 7.391682147979736\n",
      "\t\t Training MSE: 117.25286756243024 \tValidation MSE: 107.41995429992676\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8605da1861bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Find the Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-f77f97a2e78e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#output = self.linear(torch.relu(output))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    train_mse = 0.0\n",
    "    train_mae = 0.0\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        ypred = model(x.view(-1,1500,1))       \n",
    "        # Find the Loss\n",
    "        loss = criterion(ypred,y.view(-1,1))      \n",
    "        # Calculate gradients\n",
    "        loss.backward()       \n",
    "        # Update Weights\n",
    "        optimizer.step()      \n",
    "        # Calculate L1 Loss\n",
    "        train_loss += loss.item()\n",
    "        # Calculate MAE\n",
    "        ypred = ypred.detach().numpy()\n",
    "        train_mae += mean_absolute_error(ypred, y.view(-1,1))\n",
    "        # Calculate MSE\n",
    "        train_mse += mean_squared_error(ypred, y.view(-1,1))\n",
    "        # R^2\n",
    "        \n",
    "        train_preds.append(ypred)\n",
    "        \n",
    "    valid_mse = 0.0\n",
    "    valid_mae = 0.0\n",
    "    valid_loss = 0.0\n",
    "    val_preds = []\n",
    "    for x, y in val_loader:\n",
    "        # Forward Pass\n",
    "        ypred = model(x.view(-1,1500,1))\n",
    "        # Find the Loss\n",
    "        loss = criterion(ypred,y.view(-1,1))\n",
    "        # Calculate L1 Loss\n",
    "        valid_loss += loss.item()\n",
    "        # Calculate MAE\n",
    "        ypred = ypred.detach().numpy()\n",
    "        valid_mae += mean_absolute_error(ypred, y.view(-1,1))\n",
    "        # Calculate MSE\n",
    "        valid_mse += mean_squared_error(ypred, y.view(-1,1))\n",
    "        \n",
    "        val_preds.append(ypred)\n",
    "\n",
    "    history.append((train_loss/len(train_loader),valid_loss/len(val_loader)))\n",
    "    if i%2 == 0:\n",
    "        torch.save(model, 'lstm_single_output')\n",
    "        print(f'Epoch {i+1} \\t Training Loss: {train_loss/len(train_loader)} \\tValidation Loss: {valid_loss/len(val_loader)}')\n",
    "        print(f'\\t\\t Training MAE: {train_mae/len(train_loader)} \\tValidation MAE: {valid_mae/len(val_loader)}')\n",
    "        print(f'\\t\\t Training MSE: {train_mse/len(train_loader)} \\tValidation MSE: {valid_mse/len(val_loader)}')\n",
    "        print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c0686-94e3-4457-94c3-2cde0be486dc",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f7491fb-a02a-4c51-9da1-34a547645a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = torch.tensor(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "083c1a38-c3d6-4670-bb45-21d9cf4cf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'lstm_bh_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4856509-e27e-4523-ac71-16684807c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, ax=None, maxy=None, file=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(6,3))\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    val_loss = history[:,1]\n",
    "\n",
    "    ax.spines['top'].set_visible(False)    # turns off the top \"spine\" completely\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(.5)\n",
    "    ax.spines['bottom'].set_linewidth(.5)\n",
    "    ax.plot(loss, label='train_loss')\n",
    "    ax.plot(val_loss, '--', label='val_loss')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    if file:\n",
    "        plt.savefig(f\"{file}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81ed3991-053e-4bbd-8b89-6537d10c1586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history, maxy = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1a903df-0a42-4831-af50-a39e895ac712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test set actual vs predicted\n",
    "test_set = timeseries(x_test,y_test)\n",
    "test_pred = model(test_set[:][0].view(-1,1500,1)).view(-1)\n",
    "plt.scatter(test_set[:][1].view(-1), test_pred.detach().numpy(),label='predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "416656c0-b79b-4c7c-9fe4-691445b0c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model(test_set[:][0].view(-1,1500,1)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6c7a8eb-1bb1-4af6-8da0-30f82f34c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.1900, 40.3300, 45.1400, 29.3800, 29.5700, 39.8500, 22.5700, 35.1800,\n",
       "        36.5700, 33.7800, 19.5600, 32.4600, 28.6400, 15.2000, 40.3900, 23.9600,\n",
       "        27.0300, 30.1800, 32.7100, 22.5400, 29.9500, 40.6800, 13.2000, 26.3300,\n",
       "        28.6500, 37.0600, 27.5900, 30.9600, 28.2800, 24.9000, 17.0000, 38.8000,\n",
       "        37.9200, 31.8200, 27.3300, 32.8200, 46.2200, 38.8100, 26.9400, 49.9400,\n",
       "        33.3500, 61.5400, 33.8700, 41.9200, 33.8700,  6.3900, 30.6600, 30.8000,\n",
       "        36.4900, 35.0600, 38.4800, 34.4300, 32.8100, 42.7500, 33.2400, 33.5300,\n",
       "        25.8900, 37.8000, 61.1500, 29.5800, 32.7800, 44.4200, 33.6200, 31.3200,\n",
       "        37.2800, 31.5100, 31.9100, 41.6900, 30.0800, 32.3200,  4.8200,  1.1700,\n",
       "        34.9200, 30.1500, 25.3300, 30.2500, 33.1400, 41.3600, 37.5100, 37.5400,\n",
       "        39.0800, 22.3500, 40.3600, 36.7100, 30.8800, 36.7000, 32.7000, 30.6700,\n",
       "        34.7700, 12.3800, 27.9600, 38.1200, 31.1100, 36.6700, 30.2000, 28.6300,\n",
       "         9.5300, 44.9700, 30.9800, 26.0600, 32.1200, 33.4700, 36.3100, 38.2000,\n",
       "         1.1800, 22.5600, 35.2400, 25.5000, 29.8800, 12.1900, 36.5600, 41.8100,\n",
       "        35.0400, 34.6300, 31.6000, 25.7500, 22.1200, 21.7600, 25.7600, 33.9400,\n",
       "        27.1900, 29.8400, 32.4300, 59.8700, 30.5000, 38.9000, 22.2100, 19.3300,\n",
       "        31.9700, 30.7600, 30.4800, 12.1000, 31.9800, 32.8000, 35.8200, 36.3000,\n",
       "        28.5500,  1.6400, 26.5300, 27.3900, 35.9800, 34.9100, 34.1100,  8.7900,\n",
       "        56.5600, 55.7000, 31.3700, 31.6700, 28.2500, 25.1100, 35.1900,  1.6000,\n",
       "        14.3400, 31.6300,  4.1700, 44.6200, 32.9600, 32.0900, 35.0300,  3.4100,\n",
       "        40.9900, 31.3700, 30.1100, 41.7000, 15.8600, 27.4900, 30.8700, 40.9600,\n",
       "         5.7400, 36.6900, 31.7200, 31.9600, 30.7900, 38.4100, 30.6700, 11.6300,\n",
       "        36.1400, 23.3000, 34.3800, 38.0400, 39.0600, 35.7400, 29.8700, 42.2000,\n",
       "        41.0200, 31.5900, 29.8300, 34.3200,  2.8900, 42.3700, 10.6900, 42.5300,\n",
       "        40.9100, 33.2600, 37.5300, 35.0500, 31.5400, 39.4600, 30.4100, 19.9100,\n",
       "        31.4700, 33.2500, 36.4200, 34.7900, 21.6500, 30.9900, 41.0400, 32.0400,\n",
       "        37.6800, 31.0600, 29.9800, 25.1700, 25.1800, 36.5700, 34.7800,  5.1700,\n",
       "        20.7900, 23.9100, 36.5700, 36.7700, 40.9000, 36.2200, 37.9900, 36.4900,\n",
       "        34.3000,  3.8200, 31.4700, 36.7800, 31.5900, 41.7700, 30.5400, 31.2500,\n",
       "        30.6400, 33.2100, 28.8700, 40.3500, 35.4200, 31.7800, 12.1500, 35.2000,\n",
       "        30.6300, 45.8100, 33.0200, 33.7000, 32.4300, 26.8700, 35.5900, 12.2800,\n",
       "        14.3500, 23.2300, 18.5600, 51.4700, 27.2600, 38.7400, 38.0700, 41.7100,\n",
       "        30.0900,  2.1700, 40.9400, 34.2400, 32.5800, 30.9900, 47.1400, 47.1300,\n",
       "        32.0800, 27.5500, 37.9900, 30.2100, 31.3100, 33.9400,  1.6500, 39.0600,\n",
       "         9.1800, 22.9700, 31.2400, 31.2000, 28.4700, 21.8700, 61.6400, 26.2900,\n",
       "        26.1400, 34.1800, 32.2700, 48.2100, 28.2300, 22.0900, 31.8100, 30.4000,\n",
       "        40.8000, 37.1500, 38.0800, 30.6000, 39.5100, 35.9100, 32.8600,  4.6000,\n",
       "        30.7500, 25.6500, 30.7000, 34.5400, 45.4800, 40.8400, 42.6300, 33.9200,\n",
       "        16.3300, 55.4900, 27.9300, 40.9300, 36.7100, 30.7100, 37.6300, 27.9400,\n",
       "        40.4700, 30.2600, 32.9600, 30.3000, 30.9600, 47.8000, 36.2700, 32.6500,\n",
       "        46.0900, 31.2900, 41.2700, 40.9800, 41.0200, 56.7100, 27.6100, 34.8100,\n",
       "        36.2200, 23.0600, 36.2200, 25.9400, 30.2800, 30.2400, 31.4300, 12.3300,\n",
       "        33.9700, 36.2300, 30.4700, 33.7800, 31.0700, 26.4600, 29.0100, 28.2600,\n",
       "        46.1600, 37.0400, 34.9300, 32.9800, 24.1900, 43.6000,  2.2900, 36.9000,\n",
       "        35.3500, 39.8000, 33.7700,  3.1200, 45.4300, 32.9100, 25.1000, 52.2900,\n",
       "        39.3800, 12.3400, 33.3400, 37.4100, 43.4600, 41.0800, 57.4200, 41.5800,\n",
       "        30.6400, 18.3300, 41.1200, 30.4500, 31.0700, 36.4100, 40.7000, 37.1600,\n",
       "        36.3300, 41.1700,  1.7600, 10.5800, 30.9500, 41.2100, 42.9100, 26.1800,\n",
       "        22.4200, 33.4700, 38.2800, 25.1600, 36.5200, 43.1600, 33.3000, 39.9800,\n",
       "        31.0100, 25.3900, 41.8700, 31.9800, 37.5900, 17.2700,  7.6300, 36.7000,\n",
       "        27.4500, 40.5400, 47.4600, 33.5100, 33.5600, 39.9200, 35.9900, 34.3200,\n",
       "        30.7000, 27.1700, 36.3700, 41.5400, 30.5000, 24.7900, 36.4500, 32.1900,\n",
       "        18.4000, 37.5500, 26.5200, 39.6200, 24.1700, 37.2500, 31.4700, 11.7500,\n",
       "        18.2400, 31.6900, 30.1800, 47.0300, 40.8100, 39.3200, 33.8000, 21.4200,\n",
       "        31.2200, 35.1000,  2.1500, 39.7400, 53.2500, 33.4300,  2.0100, 30.6000,\n",
       "        36.5900, 26.9000,  4.6600, 40.9000, 36.4300, 14.7600, 31.7600, 40.1800,\n",
       "        24.7500, 42.3600, 31.0500, 20.8100, 22.0600, 27.1300, 28.6800, 27.7200,\n",
       "        41.1800, 40.8400, 43.4800, 41.3300, 35.2500, 31.7000, 11.2400, 39.4200,\n",
       "        28.6200, 41.0600, 35.6900, 29.8100, 38.5200, 35.0000, 31.4000, 38.3200,\n",
       "        33.9800, 31.6300, 39.7000, 31.7400, 30.9500, 41.3800, 26.0700, 48.6300,\n",
       "        39.0800, 35.6900, 36.8600, 32.8800, 39.6800, 30.0600, 31.0700, 32.2900,\n",
       "        32.0700, 34.7300, 41.4200, 39.9400, 31.7200, 64.2100, 30.6100, 32.4900,\n",
       "        32.6800, 32.2500, 33.3900, 25.1100, 22.5600, 29.5500, 26.7200, 36.1900,\n",
       "        14.2200, 39.5500, 21.9100, 26.5700, 11.3400, 38.0400, 40.0300, 31.6900,\n",
       "        27.7000, 29.9500, 29.7600, 39.8300, 34.1800, 35.4300, 35.8500, 36.4500,\n",
       "        34.5900, 29.2800, 22.3900, 37.3200, 39.0100, 38.6100, 29.0700, 24.3500,\n",
       "        34.0800, 16.9800, 29.8500, 37.0500, 32.9100, 41.3900, 22.1900, 32.0300,\n",
       "        45.4200, 33.1600, 35.8300, 31.6100, 32.0000, 38.8900, 18.5300, 30.3100,\n",
       "        39.9100,  2.3300, 31.5100, 35.4200, 26.0000, 31.0800, 32.3300, 34.9000,\n",
       "        32.5900, 15.5800, 23.1800, 22.6400, 33.9600, 14.3800, 30.8800, 58.2100,\n",
       "        22.3900, 29.3300, 38.3000, 38.8600, 25.2000, 25.1000, 33.4900, 31.1600,\n",
       "        36.1800, 35.4400, 31.3800, 45.8200, 35.6600, 23.7000, 22.5900, 35.0300,\n",
       "        29.9200, 38.3900,  3.1000,  6.3900,  1.0100, 30.0800, 36.2800, 29.5500,\n",
       "        47.8600, 32.9300, 33.2200, 30.5400, 41.5000, 30.9300, 17.9400, 34.0900,\n",
       "        32.4800, 30.7100, 32.3900, 37.0500, 52.5900, 34.3400, 25.6600, 31.5000,\n",
       "        40.7500, 35.9200, 18.5500, 30.7900, 43.1800, 26.0100, 32.5300, 32.5000,\n",
       "        72.0600, 13.5300, 47.1600, 41.2000,  8.6500, 41.1500,  3.6600, 40.4000,\n",
       "        29.2400, 36.3100, 29.6700, 34.0000, 35.9300, 22.0800, 32.5900, 42.2000,\n",
       "        40.8300, 33.8700, 40.9100, 17.4900, 18.2000, 29.6600, 27.9300, 31.7000,\n",
       "        13.8600, 36.8700, 34.0800, 31.0700, 27.4900, 28.3500, 25.3700, 33.0900,\n",
       "        16.4800, 25.7300,  7.9000, 36.8900, 33.5400, 30.9800, 37.2600, 31.0500,\n",
       "        34.1300,  4.0200, 36.8900, 33.4900, 32.1000, 32.8000, 59.5000, 39.0700,\n",
       "        31.1600, 40.7300, 42.0000, 40.7400, 31.1400, 40.1100, 32.5400, 37.5400,\n",
       "        31.6000, 36.4300, 30.0200, 28.9800, 34.2300, 33.4700, 33.6100, 35.5500,\n",
       "        39.1800, 30.1300, 33.8400, 41.1800, 50.0800, 30.8000, 34.0900, 36.9500,\n",
       "        31.7300, 31.0300, 27.3500, 35.1000, 30.0700, 21.7800, 60.0400, 37.8700,\n",
       "        48.3000, 47.0600, 38.3300, 32.5400, 47.1200, 25.9700, 37.7400, 29.8300,\n",
       "        30.3600, 30.8200, 37.7300, 41.7100, 36.6200, 59.1100, 30.9900,  8.1400,\n",
       "        31.5500, 10.6200, 55.5500, 31.2900, 30.1500, 32.4000, 39.0600, 36.6900,\n",
       "        38.8100, 34.5400, 14.3200, 25.5700, 30.5100, 55.8700, 46.8300, 32.4200,\n",
       "        37.0700, 34.3100, 28.5300, 40.9800, 29.9100, 21.6600, 38.2500, 16.9000,\n",
       "        29.7400, 12.9200, 30.1900, 42.4600, 11.7700, 40.4200, 40.2800, 33.7100,\n",
       "        32.8500, 28.8900, 33.5100, 41.0200, 35.9400, 27.7600, 46.3400, 35.5900,\n",
       "        21.7800, 59.9800, 30.0300, 39.5200,  7.0000, 36.0300, 39.4100, 31.2300,\n",
       "        40.8200, 36.3100, 49.1800, 27.1200, 34.6700, 36.3800, 30.7200, 42.1800,\n",
       "        26.5200, 35.7700, 22.4300, 21.6000, 35.6600, 24.5600, 29.3600, 22.4700,\n",
       "        47.3800, 40.6100, 30.6900, 41.0200, 26.0900, 35.2500, 37.5700, 26.8000,\n",
       "         4.7900, 42.1200, 27.0400, 21.9300, 26.5000, 30.0700, 40.7200, 10.8100,\n",
       "        29.7700, 21.8400, 22.6000, 35.7800, 32.2600, 33.5000, 26.6500, 26.0600,\n",
       "        28.6500, 29.3500, 19.8100, 28.9600, 22.3800, 31.5500, 41.3700, 32.4700,\n",
       "        28.7400, 26.4700, 37.2100, 35.9100, 37.6900,  1.7100, 14.8800, 35.9500,\n",
       "        40.5500, 36.9100, 36.2900, 10.9500, 26.4800, 33.4300, 31.5300, 30.4000,\n",
       "        29.5200, 30.4900,  1.3000, 24.4100, 36.6200, 37.8600,  1.4400, 30.5000,\n",
       "        32.3000, 30.7200,  8.4400, 31.9500, 36.1300, 22.5100, 36.4300, 41.5200,\n",
       "        27.1100, 40.7400, 30.4800, 40.4500, 41.1000, 37.6600, 30.3900, 31.1200,\n",
       "        37.3500, 40.4100, 30.8300, 38.6500, 36.7900, 37.7500, 30.5000, 35.5000,\n",
       "        30.3300, 37.3200, 27.3300, 37.0800, 28.4000, 21.8000, 41.2000, 40.8500,\n",
       "        40.8400, 31.2300, 30.7900, 62.7900,  1.5700, 32.3000, 36.4000, 40.5500,\n",
       "        37.2700, 39.2700, 13.5800, 43.7300, 22.2200, 31.4700, 35.7400, 37.3700,\n",
       "        28.2600, 35.3900, 27.2200, 28.0600, 21.8100, 29.1200, 30.7700, 40.3400,\n",
       "        29.3100, 32.1500, 33.7100, 30.6700, 25.6500, 31.2600, 47.3300, 25.5200,\n",
       "        25.7900, 35.5300, 41.3200, 41.6000, 41.8200, 34.2300, 40.8300, 28.3300,\n",
       "        35.2000, 41.9800, 30.6100, 17.2200, 56.8000, 35.9000, 30.2100, 32.4800,\n",
       "        41.8300, 31.8400, 25.6800, 30.8900, 34.1700, 33.8300, 36.0900, 41.3600,\n",
       "        29.3700, 40.0900, 25.5300, 31.0900, 35.2800, 29.9300, 31.2800, 46.1300,\n",
       "        34.8700, 38.1800, 40.9100, 25.9300, 29.2500, 34.5500, 60.4500, 18.8700,\n",
       "        40.1700,  6.5800, 26.1400, 33.2100, 16.2900, 25.8600, 31.4600, 11.7200,\n",
       "        26.2300, 31.0700, 34.8900, 30.2600, 22.3400, 30.7000, 34.2800, 37.0900,\n",
       "        30.8200, 32.4200, 37.2000, 31.3700, 34.1300, 25.3600, 42.0500, 61.1000,\n",
       "        16.4500, 28.8800, 28.9600, 27.9000, 31.4000, 42.1600, 30.8100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:][1].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4958e25-daf1-4afb-84bc-7af95c4bc6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686,\n",
       "        32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686, 32.6686],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166a699-63ba-4ec3-8b44-6f189a37d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210faf69-ae75-4de3-bf52-530b0cab0661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
